{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACIT 4610, Portfolio-2024\n",
      "\n",
      "Group-13\n",
      "\n",
      "participate: Harith Elamin Thomas Nygaard\n"
     ]
    }
   ],
   "source": [
    "print('ACIT 4610, Portfolio-2024')\n",
    "print('\\nGroup-13')\n",
    "print('\\nparticipate: Harith Elamin', 'Thomas Nygaard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools and Libraries:\n",
      "\n",
      "1- Python 3.\n",
      "\n",
      "2- OpenAI Gym for the environment.\n",
      "\n",
      "3- Deep to use Genetic Programming, implement an evolutionary algorithms.\n",
      "\n",
      "4- NumPy for numerical computations.\n",
      "\n",
      "5- pandas for data manipulation and analysis.\n",
      "\n",
      "6- requests for the process of sending and receiving data from websites.\n",
      "\n",
      "7- Matplotlib for plotting results.\n",
      "\n",
      "8- TensorFlow/PyTorch for more advanced RL algorithms like DQN.\n",
      "\n",
      "9- pymoo for for multi-objective optimization algorithms.\n",
      "\n",
      "10-Keras for the convenience of mathematical calculations\n",
      "about-time==4.2.1\n",
      "alive-progress==3.1.5\n",
      "asttokens==2.4.1\n",
      "autograd==1.7.0\n",
      "beautifulsoup4==4.12.3\n",
      "certifi==2024.8.30\n",
      "charset-normalizer==3.4.0\n",
      "cloudpickle==3.1.0\n",
      "cma==3.2.2\n",
      "colorama==0.4.6\n",
      "comm==0.2.2\n",
      "contourpy==1.3.0\n",
      "cycler==0.12.1\n",
      "deap==1.4.1\n",
      "debugpy==1.8.7\n",
      "decorator==5.1.1\n",
      "Deprecated==1.2.14\n",
      "dill==0.3.9\n",
      "executing==2.1.0\n",
      "Farama-Notifications==0.0.4\n",
      "fonttools==4.54.1\n",
      "frozendict==2.4.6\n",
      "grapheme==0.6.0\n",
      "gym==0.26.2\n",
      "gym-notices==0.0.8\n",
      "gymnasium==1.0.0\n",
      "html5lib==1.1\n",
      "idna==3.10\n",
      "ipykernel==6.29.5\n",
      "ipython==8.28.0\n",
      "jedi==0.19.1\n",
      "joblib==1.4.2\n",
      "jupyter_client==8.6.3\n",
      "jupyter_core==5.7.2\n",
      "kiwisolver==1.4.7\n",
      "lxml==5.3.0\n",
      "matplotlib==3.9.2\n",
      "matplotlib-inline==0.1.7\n",
      "multitasking==0.0.11\n",
      "nest-asyncio==1.6.0\n",
      "numpy==2.1.2\n",
      "packaging==24.1\n",
      "pandas==2.2.3\n",
      "parso==0.8.4\n",
      "peewee==3.17.7\n",
      "pillow==11.0.0\n",
      "platformdirs==4.3.6\n",
      "prompt_toolkit==3.0.48\n",
      "psutil==6.1.0\n",
      "pure_eval==0.2.3\n",
      "Pygments==2.18.0\n",
      "pymoo==0.6.1.3\n",
      "pyparsing==3.2.0\n",
      "python-dateutil==2.9.0.post0\n",
      "pytz==2024.2\n",
      "pywin32==308\n",
      "pyzmq==26.2.0\n",
      "requests==2.32.3\n",
      "scikit-fuzzy==0.5.0\n",
      "scikit-learn==1.5.2\n",
      "scipy==1.14.1\n",
      "six==1.16.0\n",
      "soupsieve==2.6\n",
      "stack-data==0.6.3\n",
      "threadpoolctl==3.5.0\n",
      "tornado==6.4.1\n",
      "traitlets==5.14.3\n",
      "typing_extensions==4.12.2\n",
      "tzdata==2024.2\n",
      "urllib3==2.2.3\n",
      "wcwidth==0.2.13\n",
      "webencodings==0.5.1\n",
      "wrapt==1.16.0\n",
      "yfinance==0.2.48\n",
      "Requirement already satisfied: gym in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.26.2)\n",
      "Collecting pygame\n",
      "  Using cached pygame-2.6.1-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.1.2)\n",
      "System version 3.13.0 (tags/v3.13.0:60403a5, Oct  7 2024, 09:38:07) [MSC v.1941 64 bit (AMD64)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for tensorflow\n"
     ]
    }
   ],
   "source": [
    "print('Tools and Libraries:')\n",
    "print('\\n1- Python 3.')\n",
    "print('\\n2- OpenAI Gym for the environment.')\n",
    "print('\\n3- Deep to use Genetic Programming, implement an evolutionary algorithms.')\n",
    "print('\\n4- NumPy for numerical computations.')\n",
    "print('\\n5- pandas for data manipulation and analysis.')\n",
    "print('\\n6- requests for the process of sending and receiving data from websites.')\n",
    "print('\\n7- Matplotlib for plotting results.')\n",
    "print('\\n8- TensorFlow/PyTorch for more advanced RL algorithms like DQN.')\n",
    "print('\\n9- pymoo for for multi-objective optimization algorithms.')\n",
    "print('\\n10-Keras for the convenience of mathematical calculations')\n",
    "\n",
    "!pip3 freeze\n",
    "!pip3 install gym pygame numpy tensorflow keras openAi matplotlib requests pandas gym deap pymoo\n",
    "\n",
    "\n",
    "import sys\n",
    "print('System version',sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 4: Solving a Real-World Problem Using Reinforcement Learning\n",
    "\n",
    "Overview \n",
    "This lab exercise aims to apply reinforcement learning techniques to solve a real-world \n",
    "problem. Students will use a publicly available dataset to train an RL agent, evaluate its \n",
    "performance, and optimize it to achieve the best possible outcome. \n",
    "\n",
    "Problem Statement: \n",
    "Autonomous Taxi Navigation \n",
    "You will develop an autonomous taxi driver who picks up passengers and drops them off at \n",
    "their destinations in the shortest possible time. The environment is a grid-based city, and the \n",
    "taxi must navigate to specific locations while avoiding obstacles, optimizing routes, and \n",
    "maximizing the efficiency of passenger pickups and drop-offs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: \n",
    "In order to utilize the Taxi-v3 environment available in the OpenAI Gym we have to interact with Taxi-v3 Environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "# Taxi environment\n",
    "env = gym.make('Taxi-v3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks: \n",
    "1. Understanding the Environment:\n",
    "A. Explore the Taxi-v3 environment.\n",
    "B. Understand the state space, action space, and reward system. \n",
    "C. Visualize the grid and how the taxi moves within it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial State:\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 5, Reward: -10, Next State: 413\n",
      "Action: 5, Reward: -10, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 1, Reward: -1, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 4, Reward: -10, Next State: 113\n",
      "Action: 0, Reward: -1, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 4, Reward: -10, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 5, Reward: -10, Next State: 213\n",
      "Action: 4, Reward: -10, Next State: 213\n",
      "Action: 5, Reward: -10, Next State: 213\n",
      "Action: 5, Reward: -10, Next State: 213\n",
      "Action: 4, Reward: -10, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 1, Reward: -1, Next State: 113\n",
      "Action: 5, Reward: -10, Next State: 113\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 0, Reward: -1, Next State: 113\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 5, Reward: -10, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 5, Reward: -10, Next State: 113\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 4, Reward: -10, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 0, Reward: -1, Next State: 233\n",
      "Action: 4, Reward: -10, Next State: 233\n",
      "Action: 4, Reward: -10, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 4, Reward: -10, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 5, Reward: -10, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 5, Reward: -10, Next State: 213\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 2, Reward: -1, Next State: 413\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 2, Reward: -1, Next State: 413\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 2, Reward: -1, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 1, Reward: -1, Next State: 133\n",
      "Action: 0, Reward: -1, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 1, Reward: -1, Next State: 133\n",
      "Action: 0, Reward: -1, Next State: 233\n",
      "Action: 4, Reward: -10, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 0, Reward: -1, Next State: 373\n",
      "Action: 4, Reward: -10, Next State: 373\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 4, Reward: -10, Next State: 373\n",
      "Action: 1, Reward: -1, Next State: 273\n",
      "Action: 0, Reward: -1, Next State: 373\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 5, Reward: -10, Next State: 393\n",
      "Action: 4, Reward: -10, Next State: 393\n",
      "Action: 5, Reward: -10, Next State: 393\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 0, Reward: -1, Next State: 493\n",
      "Action: 5, Reward: -10, Next State: 493\n",
      "Action: 0, Reward: -1, Next State: 493\n",
      "Action: 1, Reward: -1, Next State: 393\n",
      "Action: 4, Reward: -10, Next State: 393\n",
      "Action: 4, Reward: -10, Next State: 393\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 4, Reward: -10, Next State: 393\n",
      "Action: 0, Reward: -1, Next State: 493\n",
      "Action: 2, Reward: -1, Next State: 493\n",
      "Action: 0, Reward: -1, Next State: 493\n",
      "Action: 3, Reward: -1, Next State: 473\n",
      "Action: 1, Reward: -1, Next State: 373\n",
      "Action: 5, Reward: -10, Next State: 373\n",
      "Action: 5, Reward: -10, Next State: 373\n",
      "Action: 1, Reward: -1, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 0, Reward: -1, Next State: 373\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 1, Reward: -1, Next State: 293\n",
      "Action: 0, Reward: -1, Next State: 393\n",
      "Action: 4, Reward: -10, Next State: 393\n",
      "Action: 0, Reward: -1, Next State: 493\n",
      "Action: 4, Reward: -10, Next State: 493\n",
      "Action: 3, Reward: -1, Next State: 473\n",
      "Action: 1, Reward: -1, Next State: 373\n",
      "Action: 1, Reward: -1, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 0, Reward: -1, Next State: 373\n",
      "Action: 5, Reward: -10, Next State: 373\n",
      "Action: 4, Reward: -10, Next State: 373\n",
      "Action: 5, Reward: -10, Next State: 373\n",
      "Action: 5, Reward: -10, Next State: 373\n",
      "Action: 4, Reward: -10, Next State: 373\n",
      "Action: 4, Reward: -10, Next State: 373\n",
      "Action: 1, Reward: -1, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 4, Reward: -10, Next State: 53\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 2, Reward: -1, Next State: 173\n",
      "Action: 0, Reward: -1, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 2, Reward: -1, Next State: 73\n",
      "Action: 5, Reward: -10, Next State: 73\n",
      "Action: 0, Reward: -1, Next State: 173\n",
      "Action: 0, Reward: -1, Next State: 273\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 5, Reward: -10, Next State: 293\n",
      "Action: 1, Reward: -1, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 1, Reward: -1, Next State: 193\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 4, Reward: -10, Next State: 93\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 3, Reward: -1, Next State: 73\n",
      "Action: 1, Reward: -1, Next State: 73\n",
      "Action: 0, Reward: -1, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 0, Reward: -1, Next State: 393\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 4, Reward: -10, Next State: 373\n",
      "Action: 0, Reward: -1, Next State: 473\n",
      "Action: 0, Reward: -1, Next State: 473\n",
      "Action: 5, Reward: -10, Next State: 473\n",
      "Action: 1, Reward: -1, Next State: 373\n",
      "Action: 0, Reward: -1, Next State: 473\n",
      "Action: 2, Reward: -1, Next State: 493\n",
      "Action: 5, Reward: -10, Next State: 493\n",
      "Action: 4, Reward: -10, Next State: 493\n",
      "Action: 0, Reward: -1, Next State: 493\n",
      "Action: 2, Reward: -1, Next State: 493\n",
      "Action: 5, Reward: -10, Next State: 493\n",
      "Action: 0, Reward: -1, Next State: 493\n",
      "Action: 1, Reward: -1, Next State: 393\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 0, Reward: -1, Next State: 473\n",
      "Action: 3, Reward: -1, Next State: 473\n",
      "Action: 2, Reward: -1, Next State: 493\n",
      "Action: 0, Reward: -1, Next State: 493\n",
      "Action: 5, Reward: -10, Next State: 493\n",
      "Action: 5, Reward: -10, Next State: 493\n",
      "Action: 1, Reward: -1, Next State: 393\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 1, Reward: -1, Next State: 273\n",
      "Action: 0, Reward: -1, Next State: 373\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 1, Reward: -1, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 1, Reward: -1, Next State: 73\n",
      "Action: 1, Reward: -1, Next State: 73\n",
      "Action: 4, Reward: -10, Next State: 73\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 4, Reward: -10, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 4, Reward: -10, Next State: 53\n",
      "Action: 4, Reward: -10, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 2, Reward: -1, Next State: 173\n",
      "Action: 0, Reward: -1, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 2, Reward: -1, Next State: 173\n",
      "Action: 1, Reward: -1, Next State: 73\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 2, Reward: -1, Next State: 73\n",
      "Action: 4, Reward: -10, Next State: 73\n",
      "Action: 5, Reward: -10, Next State: 73\n",
      "Action: 5, Reward: -10, Next State: 73\n",
      "Action: 4, Reward: -10, Next State: 73\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 3, Reward: -1, Next State: 73\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 2, Reward: -1, Next State: 73\n",
      "Action: 5, Reward: -10, Next State: 73\n",
      "Action: 4, Reward: -10, Next State: 73\n",
      "Action: 4, Reward: -10, Next State: 73\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 5, Reward: -10, Next State: 293\n",
      "Action: 3, Reward: -1, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 4, Reward: -10, Next State: 173\n",
      "Action: 0, Reward: -1, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 1, Reward: -1, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 1, Reward: -1, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 1, Reward: -1, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 4, Reward: -10, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 4, Reward: -10, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 1, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 1, Reward: -1, Next State: 133\n",
      "Action: 5, Reward: -10, Next State: 133\n",
      "Action: 1, Reward: -1, Next State: 33\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 4, Reward: -10, Next State: 33\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 1, Reward: -1, Next State: 33\n",
      "Action: 5, Reward: -10, Next State: 33\n",
      "Action: 1, Reward: -1, Next State: 33\n",
      "Action: 4, Reward: -10, Next State: 33\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 5, Reward: -10, Next State: 13\n",
      "Action: 0, Reward: -1, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 5, Reward: -10, Next State: 113\n",
      "Action: 4, Reward: -10, Next State: 113\n",
      "Action: 4, Reward: -10, Next State: 113\n",
      "Action: 5, Reward: -10, Next State: 113\n",
      "Action: 0, Reward: -1, Next State: 213\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 5, Reward: -10, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 4, Reward: -10, Next State: 213\n",
      "Action: 1, Reward: -1, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 5, Reward: -10, Next State: 33\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 5, Reward: -10, Next State: 33\n",
      "Action: 0, Reward: -1, Next State: 133\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 4, Reward: -10, Next State: 133\n",
      "Action: 1, Reward: -1, Next State: 33\n",
      "Action: 5, Reward: -10, Next State: 33\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 4, Reward: -10, Next State: 13\n",
      "Action: 0, Reward: -1, Next State: 113\n",
      "Action: 4, Reward: -10, Next State: 113\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 4, Reward: -10, Next State: 133\n",
      "Action: 0, Reward: -1, Next State: 233\n",
      "Action: 1, Reward: -1, Next State: 133\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 5, Reward: -10, Next State: 133\n",
      "Action: 1, Reward: -1, Next State: 33\n",
      "Action: 5, Reward: -10, Next State: 33\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 4, Reward: -10, Next State: 33\n",
      "Action: 5, Reward: -10, Next State: 33\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 4, Reward: -10, Next State: 33\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 0, Reward: -1, Next State: 133\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 4, Reward: -10, Next State: 13\n",
      "Action: 5, Reward: -10, Next State: 13\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 5, Reward: -10, Next State: 13\n",
      "Action: 0, Reward: -1, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 5, Reward: -10, Next State: 113\n",
      "Action: 5, Reward: -10, Next State: 113\n",
      "Action: 5, Reward: -10, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 5, Reward: -10, Next State: 13\n",
      "Action: 4, Reward: -10, Next State: 13\n",
      "Action: 5, Reward: -10, Next State: 13\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 0, Reward: -1, Next State: 133\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 4, Reward: -10, Next State: 113\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 4, Reward: -10, Next State: 113\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 4, Reward: -10, Next State: 13\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 4, Reward: -10, Next State: 33\n",
      "Action: 4, Reward: -10, Next State: 33\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 1, Reward: -1, Next State: 33\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 0, Reward: -1, Next State: 133\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 0, Reward: -1, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 4, Reward: -10, Next State: 213\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 4, Reward: -10, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 4, Reward: -10, Next State: 453\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 1, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 5, Reward: -10, Next State: 433\n",
      "Action: 4, Reward: -10, Next State: 433\n",
      "Action: 5, Reward: -10, Next State: 433\n",
      "Action: 1, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 4, Reward: -10, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 5, Reward: -10, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 1, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 1, Reward: -1, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 5, Reward: -10, Next State: 433\n",
      "Action: 1, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 4, Reward: -10, Next State: 433\n",
      "Action: 1, Reward: -1, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 4, Reward: -10, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 5, Reward: -10, Next State: 213\n",
      "Action: 5, Reward: -10, Next State: 213\n",
      "Action: 5, Reward: -10, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 2, Reward: -1, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 5, Reward: -10, Next State: 213\n",
      "Action: 5, Reward: -10, Next State: 213\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 4, Reward: -10, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 4, Reward: -10, Next State: 233\n",
      "Action: 5, Reward: -10, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 1, Reward: -1, Next State: 113\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 0, Reward: -1, Next State: 113\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 0, Reward: -1, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 4, Reward: -10, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 0, Reward: -1, Next State: 273\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 5, Reward: -10, Next State: 293\n",
      "Action: 5, Reward: -10, Next State: 293\n",
      "Action: 0, Reward: -1, Next State: 393\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 1, Reward: -1, Next State: 273\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 5, Reward: -10, Next State: 293\n",
      "Action: 5, Reward: -10, Next State: 293\n",
      "Action: 1, Reward: -1, Next State: 193\n",
      "Action: 5, Reward: -10, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 0, Reward: -1, Next State: 393\n",
      "Action: 1, Reward: -1, Next State: 293\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 1, Reward: -1, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 3, Reward: -1, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 0, Reward: -1, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 1, Reward: -1, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 4, Reward: -10, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 4, Reward: -10, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 3, Reward: -1, Next State: 173\n",
      "Action: 0, Reward: -1, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 4, Reward: -10, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 1, Reward: -1, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 5, Reward: -10, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 0, Reward: -1, Next State: 393\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 5, Reward: -10, Next State: 393\n",
      "Action: 4, Reward: -10, Next State: 393\n",
      "Action: 5, Reward: -10, Next State: 393\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 4, Reward: -10, Next State: 393\n",
      "Action: 1, Reward: -1, Next State: 293\n",
      "Action: 1, Reward: -1, Next State: 193\n",
      "Action: 5, Reward: -10, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 1, Reward: -1, Next State: 193\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 3, Reward: -1, Next State: 73\n",
      "Action: 0, Reward: -1, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 4, Reward: -10, Next State: 173\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 4, Reward: -10, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 4, Reward: -10, Next State: 453\n",
      "Action: 4, Reward: -10, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 1, Reward: -1, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 1, Reward: -1, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 0, Reward: -1, Next State: 373\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 5, Reward: -10, Next State: 373\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 1, Reward: -1, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 0, Reward: -1, Next State: 373\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 0, Reward: -1, Next State: 473\n",
      "Action: 5, Reward: -10, Next State: 473\n",
      "Action: 1, Reward: -1, Next State: 373\n",
      "Action: 0, Reward: -1, Next State: 473\n",
      "Action: 2, Reward: -1, Next State: 493\n",
      "Action: 1, Reward: -1, Next State: 393\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 0, Reward: -1, Next State: 493\n",
      "Action: 3, Reward: -1, Next State: 473\n",
      "Action: 2, Reward: -1, Next State: 493\n",
      "Action: 1, Reward: -1, Next State: 393\n",
      "Action: 5, Reward: -10, Next State: 393\n",
      "Action: 1, Reward: -1, Next State: 293\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 1, Reward: -1, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 4, Reward: -10, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 3, Reward: -1, Next State: 73\n",
      "Action: 5, Reward: -10, Next State: 73\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 1, Reward: -1, Next State: 133\n",
      "Action: 0, Reward: -1, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 1, Reward: -1, Next State: 113\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 4, Reward: -10, Next State: 13\n",
      "Action: 5, Reward: -10, Next State: 13\n",
      "Action: 0, Reward: -1, Next State: 113\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 4, Reward: -10, Next State: 133\n",
      "Action: 4, Reward: -10, Next State: 133\n",
      "Action: 0, Reward: -1, Next State: 233\n",
      "Action: 4, Reward: -10, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 5, Reward: -10, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 5, Reward: -10, Next State: 233\n",
      "Action: 4, Reward: -10, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 5, Reward: -10, Next State: 233\n",
      "Action: 4, Reward: -10, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 5, Reward: -10, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 4, Reward: -10, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 4, Reward: -10, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 2, Reward: -1, Next State: 173\n",
      "Action: 0, Reward: -1, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 0, Reward: -1, Next State: 273\n",
      "Action: 0, Reward: -1, Next State: 373\n",
      "Action: 5, Reward: -10, Next State: 373\n",
      "Action: 1, Reward: -1, Next State: 273\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 0, Reward: -1, Next State: 393\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 1, Reward: -1, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 1, Reward: -1, Next State: 73\n",
      "Action: 4, Reward: -10, Next State: 73\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 2, Reward: -1, Next State: 73\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 3, Reward: -1, Next State: 73\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 5, Reward: -10, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 3, Reward: -1, Next State: 173\n",
      "Action: 4, Reward: -10, Next State: 173\n",
      "Action: 0, Reward: -1, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 1, Reward: -1, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 5, Reward: -10, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 5, Reward: -10, Next State: 193\n",
      "Action: 3, Reward: -1, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 4, Reward: -10, Next State: 173\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 4, Reward: -10, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 4, Reward: -10, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 0, Reward: -1, Next State: 373\n",
      "Action: 1, Reward: -1, Next State: 273\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 0, Reward: -1, Next State: 393\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 1, Reward: -1, Next State: 273\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 3, Reward: -1, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 2, Reward: -1, Next State: 73\n",
      "Action: 4, Reward: -10, Next State: 73\n",
      "Action: 0, Reward: -1, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 4, Reward: -10, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 3, Reward: -1, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 1, Reward: -1, Next State: 193\n",
      "Action: 3, Reward: -1, Next State: 173\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 0, Reward: -1, Next State: 393\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 5, Reward: -10, Next State: 393\n",
      "Action: 5, Reward: -10, Next State: 393\n",
      "Action: 1, Reward: -1, Next State: 293\n",
      "Action: 3, Reward: -1, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 4, Reward: -10, Next State: 173\n",
      "Action: 4, Reward: -10, Next State: 173\n",
      "Action: 0, Reward: -1, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 4, Reward: -10, Next State: 173\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 4, Reward: -10, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 2, Reward: -1, Next State: 73\n",
      "Action: 4, Reward: -10, Next State: 73\n",
      "Action: 4, Reward: -10, Next State: 73\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 3, Reward: -1, Next State: 173\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 2, Reward: -1, Next State: 173\n",
      "Action: 4, Reward: -10, Next State: 173\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 3, Reward: -1, Next State: 173\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 2, Reward: -1, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 5, Reward: -10, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 1, Reward: -1, Next State: 193\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 3, Reward: -1, Next State: 73\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 2, Reward: -1, Next State: 73\n",
      "Action: 1, Reward: -1, Next State: 73\n",
      "Action: 1, Reward: -1, Next State: 73\n",
      "Action: 0, Reward: -1, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 4, Reward: -10, Next State: 53\n",
      "Action: 2, Reward: -1, Next State: 73\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 3, Reward: -1, Next State: 73\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 3, Reward: -1, Next State: 73\n",
      "Action: 0, Reward: -1, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 4, Reward: -10, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 4, Reward: -10, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 4, Reward: -10, Next State: 433\n",
      "Action: 1, Reward: -1, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 4, Reward: -10, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 5, Reward: -10, Next State: 433\n",
      "Action: 1, Reward: -1, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 5, Reward: -10, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 3, Reward: -1, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 4, Reward: -10, Next State: 53\n",
      "Action: 4, Reward: -10, Next State: 53\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 2, Reward: -1, Next State: 73\n",
      "Action: 0, Reward: -1, Next State: 173\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 1, Reward: -1, Next State: 133\n",
      "Action: 5, Reward: -10, Next State: 133\n",
      "Action: 4, Reward: -10, Next State: 133\n",
      "Action: 5, Reward: -10, Next State: 133\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 1, Reward: -1, Next State: 33\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 4, Reward: -10, Next State: 13\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 1, Reward: -1, Next State: 33\n",
      "Action: 5, Reward: -10, Next State: 33\n",
      "Action: 0, Reward: -1, Next State: 133\n",
      "Action: 1, Reward: -1, Next State: 33\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 4, Reward: -10, Next State: 33\n",
      "Action: 5, Reward: -10, Next State: 33\n",
      "Action: 4, Reward: -10, Next State: 33\n",
      "Action: 4, Reward: -10, Next State: 33\n",
      "Action: 4, Reward: -10, Next State: 33\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 4, Reward: -10, Next State: 13\n",
      "Action: 5, Reward: -10, Next State: 13\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 5, Reward: -10, Next State: 13\n",
      "Action: 0, Reward: -1, Next State: 113\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 4, Reward: -10, Next State: 133\n",
      "Action: 4, Reward: -10, Next State: 133\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 0, Reward: -1, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 1, Reward: -1, Next State: 113\n",
      "Action: 0, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 2, Reward: -1, Next State: 413\n",
      "Action: 2, Reward: -1, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 2, Reward: -1, Next State: 413\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 5, Reward: -10, Next State: 413\n",
      "Action: 2, Reward: -1, Next State: 413\n",
      "Action: 5, Reward: -10, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 5, Reward: -10, Next State: 413\n",
      "Action: 5, Reward: -10, Next State: 413\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 5, Reward: -10, Next State: 413\n",
      "Action: 2, Reward: -1, Next State: 413\n",
      "Action: 2, Reward: -1, Next State: 413\n",
      "Action: 2, Reward: -1, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 5, Reward: -10, Next State: 413\n",
      "Action: 2, Reward: -1, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 2, Reward: -1, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 2, Reward: -1, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 4, Reward: -10, Next State: 213\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 4, Reward: -10, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 1, Reward: -1, Next State: 133\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 5, Reward: -10, Next State: 133\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 4, Reward: -10, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 0, Reward: -1, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 5, Reward: -10, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 1, Reward: -1, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 3, Reward: -1, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 1, Reward: -1, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 5, Reward: -10, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 4, Reward: -10, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 1, Reward: -1, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 1, Reward: -1, Next State: 333\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 4, Reward: -10, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 4, Reward: -10, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 4, Reward: -10, Next State: 433\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 1, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 4, Reward: -10, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 1, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 4, Reward: -10, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 4, Reward: -10, Next State: 453\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 4, Reward: -10, Next State: 453\n",
      "Action: 4, Reward: -10, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 5, Reward: -10, Next State: 433\n",
      "Action: 1, Reward: -1, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 5, Reward: -10, Next State: 293\n",
      "Action: 5, Reward: -10, Next State: 293\n",
      "Action: 3, Reward: -1, Next State: 273\n",
      "Action: 0, Reward: -1, Next State: 373\n",
      "Action: 1, Reward: -1, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 4, Reward: -10, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 4, Reward: -10, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 4, Reward: -10, Next State: 433\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 1, Reward: -1, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 4, Reward: -10, Next State: 233\n",
      "Action: 5, Reward: -10, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 1, Reward: -1, Next State: 113\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 0, Reward: -1, Next State: 213\n",
      "Action: 5, Reward: -10, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 5, Reward: -10, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 1, Reward: -1, Next State: 333\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 5, Reward: -10, Next State: 433\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 1, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 5, Reward: -10, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 4, Reward: -10, Next State: 213\n",
      "Action: 4, Reward: -10, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 1, Reward: -1, Next State: 113\n",
      "Action: 4, Reward: -10, Next State: 113\n",
      "Action: 0, Reward: -1, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 1, Reward: -1, Next State: 73\n",
      "Action: 5, Reward: -10, Next State: 73\n",
      "Action: 5, Reward: -10, Next State: 73\n",
      "Action: 1, Reward: -1, Next State: 73\n",
      "Action: 0, Reward: -1, Next State: 173\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 2, Reward: -1, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 0, Reward: -1, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 2, Reward: -1, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 4, Reward: -10, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 4, Reward: -10, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 1, Reward: -1, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 4, Reward: -10, Next State: 433\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 4, Reward: -10, Next State: 453\n",
      "Action: 1, Reward: -1, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 5, Reward: -10, Next State: 433\n",
      "Action: 1, Reward: -1, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 4, Reward: -10, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 4, Reward: -10, Next State: 433\n",
      "Action: 1, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 5, Reward: -10, Next State: 233\n",
      "Action: 5, Reward: -10, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 2, Reward: -1, Next State: 173\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 5, Reward: -10, Next State: 193\n",
      "Action: 5, Reward: -10, Next State: 193\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 3, Reward: -1, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 2, Reward: -1, Next State: 173\n",
      "Action: 0, Reward: -1, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 1, Reward: -1, Next State: 193\n",
      "Action: 3, Reward: -1, Next State: 173\n",
      "Action: 1, Reward: -1, Next State: 73\n",
      "Action: 1, Reward: -1, Next State: 73\n",
      "Action: 0, Reward: -1, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 0, Reward: -1, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 5, Reward: -10, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 5, Reward: -10, Next State: 293\n",
      "Action: 3, Reward: -1, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 0, Reward: -1, Next State: 373\n",
      "Action: 4, Reward: -10, Next State: 373\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 5, Reward: -10, Next State: 373\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 1, Reward: -1, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 1, Reward: -1, Next State: 133\n",
      "Action: 4, Reward: -10, Next State: 133\n",
      "Action: 4, Reward: -10, Next State: 133\n",
      "Action: 1, Reward: -1, Next State: 33\n",
      "Action: 1, Reward: -1, Next State: 33\n",
      "Action: 5, Reward: -10, Next State: 33\n",
      "Action: 0, Reward: -1, Next State: 133\n",
      "Action: 0, Reward: -1, Next State: 233\n",
      "Action: 5, Reward: -10, Next State: 233\n",
      "Action: 1, Reward: -1, Next State: 133\n",
      "Action: 4, Reward: -10, Next State: 133\n",
      "Action: 4, Reward: -10, Next State: 133\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 5, Reward: -10, Next State: 113\n",
      "Action: 5, Reward: -10, Next State: 113\n",
      "Action: 5, Reward: -10, Next State: 113\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 0, Reward: -1, Next State: 113\n",
      "Action: 5, Reward: -10, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 4, Reward: -10, Next State: 13\n",
      "Action: 0, Reward: -1, Next State: 113\n",
      "Action: 5, Reward: -10, Next State: 113\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 0, Reward: -1, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 4, Reward: -10, Next State: 213\n",
      "Action: 5, Reward: -10, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 3, Reward: -1, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 2, Reward: -1, Next State: 173\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 1, Reward: -1, Next State: 193\n",
      "Action: 5, Reward: -10, Next State: 193\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 3, Reward: -1, Next State: 173\n",
      "Action: 1, Reward: -1, Next State: 73\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 5, Reward: -10, Next State: 193\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 0, Reward: -1, Next State: 393\n",
      "Action: 5, Reward: -10, Next State: 393\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 5, Reward: -10, Next State: 393\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 0, Reward: -1, Next State: 493\n",
      "Action: 1, Reward: -1, Next State: 393\n",
      "Action: 5, Reward: -10, Next State: 393\n",
      "Action: 5, Reward: -10, Next State: 393\n",
      "Action: 4, Reward: -10, Next State: 393\n",
      "Action: 5, Reward: -10, Next State: 393\n",
      "Action: 5, Reward: -10, Next State: 393\n",
      "Action: 0, Reward: -1, Next State: 493\n",
      "Action: 2, Reward: -1, Next State: 493\n",
      "Action: 3, Reward: -1, Next State: 473\n",
      "Action: 1, Reward: -1, Next State: 373\n",
      "Action: 4, Reward: -10, Next State: 373\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 4, Reward: -10, Next State: 373\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 1, Reward: -1, Next State: 293\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 0, Reward: -1, Next State: 393\n",
      "Action: 4, Reward: -10, Next State: 393\n",
      "Action: 0, Reward: -1, Next State: 493\n",
      "Action: 3, Reward: -1, Next State: 473\n",
      "Action: 1, Reward: -1, Next State: 373\n",
      "Action: 5, Reward: -10, Next State: 373\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 0, Reward: -1, Next State: 473\n",
      "Action: 4, Reward: -1, Next State: 477\n",
      "Action: 3, Reward: -1, Next State: 477\n",
      "Action: 3, Reward: -1, Next State: 477\n",
      "Action: 1, Reward: -1, Next State: 377\n",
      "Action: 0, Reward: -1, Next State: 477\n",
      "Action: 4, Reward: -10, Next State: 477\n",
      "Action: 3, Reward: -1, Next State: 477\n",
      "Action: 0, Reward: -1, Next State: 477\n",
      "Action: 3, Reward: -1, Next State: 477\n",
      "Action: 1, Reward: -1, Next State: 377\n",
      "Action: 4, Reward: -10, Next State: 377\n",
      "Action: 0, Reward: -1, Next State: 477\n",
      "Action: 2, Reward: -1, Next State: 497\n",
      "Action: 1, Reward: -1, Next State: 397\n",
      "Action: 2, Reward: -1, Next State: 397\n",
      "Action: 1, Reward: -1, Next State: 297\n",
      "Action: 1, Reward: -1, Next State: 197\n",
      "Action: 4, Reward: -10, Next State: 197\n",
      "Action: 2, Reward: -1, Next State: 197\n",
      "Action: 3, Reward: -1, Next State: 177\n",
      "Action: 5, Reward: -10, Next State: 177\n",
      "Action: 1, Reward: -1, Next State: 77\n",
      "Action: 3, Reward: -1, Next State: 57\n",
      "Action: 1, Reward: -1, Next State: 57\n",
      "Action: 3, Reward: -1, Next State: 57\n",
      "Action: 0, Reward: -1, Next State: 157\n",
      "Action: 4, Reward: -10, Next State: 157\n",
      "Action: 2, Reward: -1, Next State: 177\n",
      "Action: 5, Reward: -10, Next State: 177\n",
      "Action: 4, Reward: -10, Next State: 177\n",
      "Action: 4, Reward: -10, Next State: 177\n",
      "Action: 2, Reward: -1, Next State: 197\n",
      "Action: 0, Reward: -1, Next State: 297\n",
      "Action: 2, Reward: -1, Next State: 297\n",
      "Action: 1, Reward: -1, Next State: 197\n",
      "Action: 5, Reward: -10, Next State: 197\n",
      "Action: 4, Reward: -10, Next State: 197\n",
      "Action: 4, Reward: -10, Next State: 197\n",
      "Action: 0, Reward: -1, Next State: 297\n",
      "Action: 0, Reward: -1, Next State: 397\n",
      "Action: 0, Reward: -1, Next State: 497\n",
      "Action: 3, Reward: -1, Next State: 477\n",
      "Action: 4, Reward: -10, Next State: 477\n",
      "Action: 0, Reward: -1, Next State: 477\n",
      "Action: 1, Reward: -1, Next State: 377\n",
      "Action: 3, Reward: -1, Next State: 377\n",
      "Action: 5, Reward: -10, Next State: 377\n",
      "Action: 5, Reward: -10, Next State: 377\n",
      "Action: 5, Reward: -10, Next State: 377\n",
      "Action: 2, Reward: -1, Next State: 397\n",
      "Action: 0, Reward: -1, Next State: 497\n",
      "Action: 1, Reward: -1, Next State: 397\n",
      "Action: 4, Reward: -10, Next State: 397\n",
      "Action: 0, Reward: -1, Next State: 497\n",
      "Action: 5, Reward: -10, Next State: 497\n",
      "Action: 2, Reward: -1, Next State: 497\n",
      "Action: 4, Reward: -10, Next State: 497\n",
      "Action: 1, Reward: -1, Next State: 397\n",
      "Action: 3, Reward: -1, Next State: 377\n",
      "Action: 4, Reward: -10, Next State: 377\n",
      "Action: 2, Reward: -1, Next State: 397\n",
      "Action: 3, Reward: -1, Next State: 377\n",
      "Action: 1, Reward: -1, Next State: 277\n",
      "Action: 5, Reward: -10, Next State: 277\n",
      "Action: 1, Reward: -1, Next State: 177\n",
      "Action: 5, Reward: -10, Next State: 177\n",
      "Action: 2, Reward: -1, Next State: 197\n",
      "Action: 1, Reward: -1, Next State: 97\n",
      "Action: 5, Reward: 20, Next State: 85\n",
      "Total reward: -7921\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "# Create the Taxi environment\n",
    "env = gym.make('Taxi-v3')\n",
    "\n",
    "# Reset the environment to start a new episode\n",
    "state, info = env.reset()  # Reset now returns (state, info)\n",
    "\n",
    "# Render the initial state of the environment\n",
    "print(\"Initial State:\")\n",
    "env.render()\n",
    "\n",
    "# Interact with the environment by taking random actions\n",
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "while not done:\n",
    "    # Take a random action\n",
    "    action = env.action_space.sample()  # Random action\n",
    "    next_state, reward, done, truncated, info = env.step(action)  # Step returns a 5-tuple\n",
    "\n",
    "    # Accumulate the reward\n",
    "    total_reward += reward\n",
    "\n",
    "    # Print out the current step information\n",
    "    print(f\"Action: {action}, Reward: {reward}, Next State: {next_state}\")\n",
    "    env.render()  # Render the environment to see the new state\n",
    "\n",
    "# Print the total reward after the episode ends\n",
    "print(f\"Total reward: {total_reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward after 3 moves: -12\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Create the Taxi environment\n",
    "env = gym.make('Taxi-v3')\n",
    "\n",
    "# Function to decode the state from integer representation\n",
    "def decode_state(state):\n",
    "    # The Taxi environment is a 5x5 grid, with 4 possible locations for passengers (0-4)\n",
    "    # and 4 possible locations for the destination (0-4).\n",
    "    # Total state space: 5x5x5x5x4 = 500 states.\n",
    "\n",
    "    grid_size = 5\n",
    "    passenger_positions = 4\n",
    "    destination_positions = 4\n",
    "\n",
    "    # Decode the state (state is a single integer)\n",
    "    taxi_pos = state % (grid_size * grid_size)  # Taxi's position (0-24)\n",
    "    passenger_idx = (state // (grid_size * grid_size)) % passenger_positions  # Passenger's location (0-4)\n",
    "    destination_idx = (state // (grid_size * grid_size * passenger_positions)) % destination_positions  # Destination's location (0-4)\n",
    "    \n",
    "    taxi_row, taxi_col = divmod(taxi_pos, grid_size)  # Taxi's row and column\n",
    "    passenger_pos = passenger_idx  # Passenger's position (integer representation)\n",
    "    destination_pos = destination_idx  # Destination's position (integer representation)\n",
    "\n",
    "    return taxi_row, taxi_col, passenger_pos, destination_pos\n",
    "\n",
    "# Function to render the environment as a plot\n",
    "def render_grid(state):\n",
    "    grid_size = 5\n",
    "    taxi_row, taxi_col, passenger_pos, destination_pos = decode_state(state)\n",
    "    \n",
    "    # Create a 5x5 grid\n",
    "    grid = np.zeros((grid_size, grid_size))\n",
    "\n",
    "    # Mark taxi, passenger, and destination positions\n",
    "    grid[taxi_row, taxi_col] = 1  # Taxi's position (1)\n",
    "    grid[passenger_pos // grid_size, passenger_pos % grid_size] = 2  # Passenger's position (2)\n",
    "    grid[destination_pos // grid_size, destination_pos % grid_size] = 3  # Destination's position (3)\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(grid, cmap=\"viridis\", origin=\"upper\", extent=(0, grid_size, 0, grid_size))\n",
    "    \n",
    "    # Grid labels and settings\n",
    "    plt.grid(True)\n",
    "    plt.xticks(range(5))\n",
    "    plt.yticks(range(5))\n",
    "\n",
    "    # Add text labels for taxi (T), passenger (P), and destination (D)\n",
    "    plt.text(taxi_col, taxi_row, \"T\", ha='center', va='center', fontsize=12, color='white')\n",
    "    plt.text(passenger_pos % grid_size, passenger_pos // grid_size, \"P\", ha='center', va='center', fontsize=12, color='white')\n",
    "    plt.text(destination_pos % grid_size, destination_pos // grid_size, \"D\", ha='center', va='center', fontsize=12, color='white')\n",
    "\n",
    "    plt.title(\"Taxi Environment\")\n",
    "    plt.show()\n",
    "\n",
    "# Reset the environment and start an episode\n",
    "state, info = env.reset()  # This will return state as an integer and info as a dictionary\n",
    "done = False\n",
    "total_reward = 0\n",
    "moves = 0  # To keep track of the number of moves\n",
    "\n",
    "# Interact with the environment by taking random actions\n",
    "while not done and moves < 3:  # Limit to 3 moves\n",
    "    # Render the environment\n",
    "    render_grid(state)\n",
    "    \n",
    "    # Take a random action\n",
    "    action = env.action_space.sample()  # Random action\n",
    "    next_state, reward, done, truncated, info = env.step(action)  # Step the environment\n",
    "    \n",
    "    # Accumulate reward\n",
    "    total_reward += reward\n",
    "    \n",
    "    # Update the state\n",
    "    state = next_state\n",
    "\n",
    "    # Increment move counter\n",
    "    moves += 1\n",
    "\n",
    "    # Pause to create animation effect\n",
    "    time.sleep(1)\n",
    "\n",
    "# Print the total reward after the episode ends\n",
    "print(f\"Total reward after {moves} moves: {total_reward}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Setting Up the RL Agent: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100/1000, Total Reward: -118\n",
      "Episode 200/1000, Total Reward: -145\n",
      "Episode 300/1000, Total Reward: -121\n",
      "Episode 400/1000, Total Reward: -112\n",
      "Episode 500/1000, Total Reward: -50\n",
      "Episode 600/1000, Total Reward: -139\n",
      "Episode 700/1000, Total Reward: -12\n",
      "Episode 800/1000, Total Reward: 5\n",
      "Episode 900/1000, Total Reward: -208\n",
      "Episode 1000/1000, Total Reward: -12\n",
      "Testing learned policy:\n",
      "Total reward after training: 12\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Create the Taxi environment\n",
    "env = gym.make('Taxi-v3')\n",
    "\n",
    "# Initialize the Q-table with zeros: (state_space, action_space)\n",
    "state_space = env.observation_space.n  # Total number of states (500 for Taxi-v3)\n",
    "action_space = env.action_space.n  # Total number of actions (6 for Taxi-v3)\n",
    "Q = np.zeros((state_space, action_space))\n",
    "\n",
    "# Hyperparameters for Q-learning\n",
    "alpha = 0.1  # Learning rate\n",
    "gamma = 0.99  # Discount factor\n",
    "epsilon = 0.1  # Exploration rate (epsilon-greedy)\n",
    "episodes = 1000  # Number of episodes to train the agent\n",
    "max_steps_per_episode = 100  # Max steps per episode\n",
    "\n",
    "# Epsilon-greedy action selection\n",
    "def epsilon_greedy(state):\n",
    "    if random.uniform(0, 1) < epsilon:\n",
    "        return env.action_space.sample()  # Explore: take random action\n",
    "    else:\n",
    "        return np.argmax(Q[state])  # Exploit: take action with highest Q-value\n",
    "\n",
    "# Train the agent\n",
    "for episode in range(episodes):\n",
    "    state, info = env.reset()  # Reset the environment and get the initial state\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    for step in range(max_steps_per_episode):\n",
    "        action = epsilon_greedy(state)  # Select action based on epsilon-greedy policy\n",
    "        next_state, reward, done, truncated, info = env.step(action)  # Take action\n",
    "        \n",
    "        # Update Q-value using the Q-learning formula\n",
    "        best_next_action = np.argmax(Q[next_state])  # Max Q-value for next state\n",
    "        Q[state, action] = Q[state, action] + alpha * (reward + gamma * Q[next_state, best_next_action] - Q[state, action])\n",
    "        \n",
    "        total_reward += reward\n",
    "        state = next_state  # Move to the next state\n",
    "        \n",
    "        if done:  # If the episode is done\n",
    "            break\n",
    "    \n",
    "    # Print the total reward at the end of each episode\n",
    "    if (episode + 1) % 100 == 0:\n",
    "        print(f\"Episode {episode + 1}/{episodes}, Total Reward: {total_reward}\")\n",
    "\n",
    "# Test the learned policy (after training)\n",
    "state, info = env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "print(\"Testing learned policy:\")\n",
    "while not done:\n",
    "    action = np.argmax(Q[state])  # Choose the best action based on learned Q-table\n",
    "    next_state, reward, done, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    state = next_state\n",
    "    env.render()  # Optionally render the environment to visualize the steps\n",
    "\n",
    "print(f\"Total reward after training: {total_reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100/1000, Total Reward: -127\n",
      "Episode 200/1000, Total Reward: -118\n",
      "Episode 300/1000, Total Reward: -154\n",
      "Episode 400/1000, Total Reward: -118\n",
      "Episode 500/1000, Total Reward: -115\n",
      "Episode 600/1000, Total Reward: -127\n",
      "Episode 700/1000, Total Reward: 11\n",
      "Episode 800/1000, Total Reward: -60\n",
      "Episode 900/1000, Total Reward: -107\n",
      "Episode 1000/1000, Total Reward: 13\n",
      "Testing learned policy:\n",
      "Total reward after training: 10\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Create the Taxi environment\n",
    "env = gym.make('Taxi-v3')\n",
    "\n",
    "# Initialize the Q-table with zeros: (state_space, action_space)\n",
    "state_space = env.observation_space.n  # Number of possible states (500)\n",
    "action_space = env.action_space.n  # Number of possible actions (6)\n",
    "Q = np.zeros((state_space, action_space))  # Initialize the Q-table\n",
    "\n",
    "# Hyperparameters for Q-learning\n",
    "alpha = 0.1  # Learning rate (how much new information overrides the old)\n",
    "gamma = 0.99  # Discount factor (how much we care about future rewards)\n",
    "epsilon = 0.1  # Exploration rate (probability of exploring instead of exploiting)\n",
    "episodes = 1000  # Number of episodes to train the agent\n",
    "max_steps_per_episode = 100  # Max steps per episode\n",
    "\n",
    "# Epsilon-greedy action selection function\n",
    "def epsilon_greedy(state):\n",
    "    if random.uniform(0, 1) < epsilon:\n",
    "        return env.action_space.sample()  # Explore: take a random action\n",
    "    else:\n",
    "        return np.argmax(Q[state])  # Exploit: take action with highest Q-value\n",
    "\n",
    "# Train the agent\n",
    "for episode in range(episodes):\n",
    "    state, info = env.reset()  # Reset the environment at the start of each episode\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    for step in range(max_steps_per_episode):\n",
    "        # Select an action based on epsilon-greedy policy\n",
    "        action = epsilon_greedy(state)\n",
    "        \n",
    "        # Take the action and observe the reward and next state\n",
    "        next_state, reward, done, truncated, info = env.step(action)\n",
    "        \n",
    "        # Q-value update using the Q-learning formula\n",
    "        best_next_action = np.argmax(Q[next_state])  # Max Q-value for next state\n",
    "        Q[state, action] = Q[state, action] + alpha * (reward + gamma * Q[next_state, best_next_action] - Q[state, action])\n",
    "        \n",
    "        total_reward += reward\n",
    "        state = next_state  # Update the state to the next state\n",
    "        \n",
    "        if done:  # If the episode is done, break out of the loop\n",
    "            break\n",
    "    \n",
    "    # Optionally, print the total reward for every 100th episode\n",
    "    if (episode + 1) % 100 == 0:\n",
    "        print(f\"Episode {episode + 1}/{episodes}, Total Reward: {total_reward}\")\n",
    "\n",
    "# Optionally: Testing phase (after training)\n",
    "state, info = env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "print(\"Testing learned policy:\")\n",
    "while not done:\n",
    "    action = np.argmax(Q[state])  # Exploit the learned policy (choose the action with the highest Q-value)\n",
    "    next_state, reward, done, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    state = next_state\n",
    "    env.render()  # Optionally render the environment to visualize the steps\n",
    "\n",
    "print(f\"Total reward after training: {total_reward}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the RL Agent:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Train the RL agent on the Taxi-v3 environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100/1000, Total Reward: -118\n",
      "Episode 200/1000, Total Reward: -84\n",
      "Episode 300/1000, Total Reward: -127\n",
      "Episode 400/1000, Total Reward: -154\n",
      "Episode 500/1000, Total Reward: -127\n",
      "Episode 600/1000, Total Reward: -136\n",
      "Episode 700/1000, Total Reward: -154\n",
      "Episode 800/1000, Total Reward: -136\n",
      "Episode 900/1000, Total Reward: -3\n",
      "Episode 1000/1000, Total Reward: -53\n",
      "Testing learned policy:\n",
      "Total reward after training: 11\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Create the Taxi environment\n",
    "env = gym.make('Taxi-v3')\n",
    "\n",
    "# Initialize the Q-table with zeros: (state_space, action_space)\n",
    "state_space = env.observation_space.n  # Number of possible states (500)\n",
    "action_space = env.action_space.n  # Number of possible actions (6)\n",
    "Q = np.zeros((state_space, action_space))  # Initialize the Q-table\n",
    "\n",
    "# Hyperparameters for Q-learning\n",
    "alpha = 0.1  # Learning rate (how much new information overrides the old)\n",
    "gamma = 0.99  # Discount factor (how much we care about future rewards)\n",
    "epsilon = 0.1  # Exploration rate (probability of exploring instead of exploiting)\n",
    "episodes = 1000  # Number of episodes to train the agent\n",
    "max_steps_per_episode = 100  # Max steps per episode\n",
    "\n",
    "# Epsilon-greedy action selection function\n",
    "def epsilon_greedy(state):\n",
    "    if random.uniform(0, 1) < epsilon:\n",
    "        return env.action_space.sample()  # Explore: take a random action\n",
    "    else:\n",
    "        return np.argmax(Q[state])  # Exploit: take action with highest Q-value\n",
    "\n",
    "# Training the agent\n",
    "for episode in range(episodes):\n",
    "    state, info = env.reset()  # Reset the environment at the start of each episode\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    for step in range(max_steps_per_episode):\n",
    "        # Select an action based on epsilon-greedy policy\n",
    "        action = epsilon_greedy(state)\n",
    "        \n",
    "        # Take the action and observe the reward and next state\n",
    "        next_state, reward, done, truncated, info = env.step(action)\n",
    "        \n",
    "        # Q-value update using the Q-learning formula\n",
    "        best_next_action = np.argmax(Q[next_state])  # Max Q-value for next state\n",
    "        Q[state, action] = Q[state, action] + alpha * (reward + gamma * Q[next_state, best_next_action] - Q[state, action])\n",
    "        \n",
    "        total_reward += reward\n",
    "        state = next_state  # Update the state to the next state\n",
    "        \n",
    "        if done:  # If the episode is done, break out of the loop\n",
    "            break\n",
    "    \n",
    "    # Optionally, print the total reward for every 100th episode\n",
    "    if (episode + 1) % 100 == 0:\n",
    "        print(f\"Episode {episode + 1}/{episodes}, Total Reward: {total_reward}\")\n",
    "\n",
    "# Optionally: Testing phase (after training)\n",
    "state, info = env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "print(\"Testing learned policy:\")\n",
    "while not done:\n",
    "    action = np.argmax(Q[state])  # Exploit the learned policy (choose the action with the highest Q-value)\n",
    "    next_state, reward, done, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    state = next_state\n",
    "    env.render()  # Optionally render the environment to visualize the steps\n",
    "\n",
    "print(f\"Total reward after training: {total_reward}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Tune hyperparameters such as learning rate, discount factor, and exploration \n",
    "strategy (-greedy). \n",
    "\n",
    "Q-learning with Tuned Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the Taxi environment\n",
    "env = gym.make('Taxi-v3')\n",
    "\n",
    "# Hyperparameters for Q-learning (These values will be tuned)\n",
    "alphas = [0.1, 0.2, 0.3]  # Learning rates to test\n",
    "gammas = [0.9, 0.95, 0.99]  # Discount factors to test\n",
    "epsilons = [0.1, 0.2, 0.3]  # Exploration rates to test\n",
    "episodes = 1000  # Number of episodes to train the agent\n",
    "max_steps_per_episode = 100  # Max steps per episode\n",
    "\n",
    "# Function to train the agent with specific hyperparameters\n",
    "def train_agent(alpha, gamma, epsilon):\n",
    "    state_space = env.observation_space.n  # Number of possible states (500)\n",
    "    action_space = env.action_space.n  # Number of possible actions (6)\n",
    "    Q = np.zeros((state_space, action_space))  # Initialize the Q-table\n",
    "\n",
    "    # Epsilon-greedy action selection function\n",
    "    def epsilon_greedy(state):\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            return env.action_space.sample()  # Explore: take a random action\n",
    "        else:\n",
    "            return np.argmax(Q[state])  # Exploit: take action with highest Q-value\n",
    "    \n",
    "    # Training loop\n",
    "    total_rewards = []  # To track rewards across episodes\n",
    "    for episode in range(episodes):\n",
    "        state, info = env.reset()  # Reset the environment at the start of each episode\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        \n",
    "        for step in range(max_steps_per_episode):\n",
    "            # Select an action based on epsilon-greedy policy\n",
    "            action = epsilon_greedy(state)\n",
    "            \n",
    "            # Take the action and observe the reward and next state\n",
    "            next_state, reward, done, truncated, info = env.step(action)\n",
    "            \n",
    "            # Q-value update using the Q-learning formula\n",
    "            best_next_action = np.argmax(Q[next_state])  # Max Q-value for next state\n",
    "            Q[state, action] = Q[state, action] + alpha * (reward + gamma * Q[next_state, best_next_action] - Q[state, action])\n",
    "            \n",
    "            total_reward += reward\n",
    "            state = next_state  # Update the state to the next state\n",
    "            \n",
    "            if done:  # If the episode is done, break out of the loop\n",
    "                break\n",
    "        \n",
    "        total_rewards.append(total_reward)  # Track total reward for the episode\n",
    "\n",
    "        # Optionally, print the total reward for every 100th episode\n",
    "        if (episode + 1) % 100 == 0:\n",
    "            print(f\"Alpha: {alpha}, Gamma: {gamma}, Epsilon: {epsilon}, Episode {episode + 1}/{episodes}, Total Reward: {total_reward}\")\n",
    "\n",
    "    # Return the total rewards for each episode for analysis\n",
    "    return total_rewards\n",
    "\n",
    "# Tune hyperparameters\n",
    "# We will store the total rewards for different combinations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of the trained RL agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_agent(alpha, gamma, epsilon, episodes=100):\n",
    "    \"\"\"\n",
    "    Evaluates the trained Q-learning agent by running the agent with a greedy policy.\n",
    "    \n",
    "    Arguments:\n",
    "    - alpha: learning rate (not used during evaluation)\n",
    "    - gamma: discount factor (not used during evaluation)\n",
    "    - epsilon: exploration rate (not used during evaluation)\n",
    "    - episodes: number of episodes to evaluate\n",
    "    \n",
    "    Returns:\n",
    "    - average_reward: average reward over all test episodes\n",
    "    - steps_per_episode: list of steps per episode\n",
    "    \"\"\"\n",
    "    state_space = env.observation_space.n  # Number of possible states (500)\n",
    "    action_space = env.action_space.n  # Number of possible actions (6)\n",
    "    Q = np.zeros((state_space, action_space))  # Initialize the Q-table\n",
    "\n",
    "    # Re-train the agent for a single time to obtain the Q-table\n",
    "    rewards = train_agent(alpha, gamma, epsilon)  # Use the learned Q-values\n",
    "    \n",
    "    # Set epsilon to 0 (no exploration) for evaluation\n",
    "    epsilon = 0.0\n",
    "    total_reward = 0\n",
    "    steps_per_episode = []  # List to track the number of steps in each episode\n",
    "\n",
    "    # Evaluate the agent on multiple test episodes\n",
    "    for episode in range(episodes):\n",
    "        state, info = env.reset()  # Reset the environment\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "        steps = 0\n",
    "        \n",
    "        while not done:\n",
    "            action = np.argmax(Q[state])  # Greedy action (exploit the learned policy)\n",
    "            next_state, reward, done, truncated, info = env.step(action)\n",
    "            episode_reward += reward\n",
    "            steps += 1\n",
    "            state = next_state  # Move to next state\n",
    "        \n",
    "        total_reward += episode_reward\n",
    "        steps_per_episode.append(steps)\n",
    "    \n",
    "    # Calculate average reward per episode\n",
    "    average_reward = total_reward / episodes\n",
    "    \n",
    "    return average_reward, steps_per_episode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the Taxi environment\n",
    "env = gym.make('Taxi-v3')\n",
    "\n",
    "# Hyperparameters for Q-learning (These values will be tuned)\n",
    "alphas = [0.1, 0.2, 0.3]  # Learning rates to test\n",
    "gammas = [0.9, 0.95, 0.99]  # Discount factors to test\n",
    "epsilons = [0.1, 0.2, 0.3]  # Exploration rates to test\n",
    "episodes = 1000  # Number of episodes to train the agent\n",
    "max_steps_per_episode = 100  # Max steps per episode\n",
    "\n",
    "# Function to train the agent with specific hyperparameters\n",
    "def train_agent(alpha, gamma, epsilon):\n",
    "    state_space = env.observation_space.n  # Number of possible states (500)\n",
    "    action_space = env.action_space.n  # Number of possible actions (6)\n",
    "    Q = np.zeros((state_space, action_space))  # Initialize the Q-table\n",
    "\n",
    "    # Epsilon-greedy action selection function\n",
    "    def epsilon_greedy(state):\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            return env.action_space.sample()  # Explore: take a random action\n",
    "        else:\n",
    "            return np.argmax(Q[state])  # Exploit: take action with highest Q-value\n",
    "    \n",
    "    # Training loop\n",
    "    total_rewards = []  # To track rewards across episodes\n",
    "    cumulative_rewards = []  # To track cumulative rewards over time\n",
    "    total_reward = 0  # Initialize total reward for cumulative plot\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        state, info = env.reset()  # Reset the environment at the start of each episode\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "        \n",
    "        for step in range(max_steps_per_episode):\n",
    "            # Select an action based on epsilon-greedy policy\n",
    "            action = epsilon_greedy(state)\n",
    "            \n",
    "            # Take the action and observe the reward and next state\n",
    "            next_state, reward, done, truncated, info = env.step(action)\n",
    "            \n",
    "            # Q-value update using the Q-learning formula\n",
    "            best_next_action = np.argmax(Q[next_state])  # Max Q-value for next state\n",
    "            Q[state, action] = Q[state, action] + alpha * (reward + gamma * Q[next_state, best_next_action] - Q[state, action])\n",
    "            \n",
    "            episode_reward += reward\n",
    "            state = next_state  # Update the state to the next state\n",
    "            \n",
    "            if done:  # If the episode is done, break out of the loop\n",
    "                break\n",
    "        \n",
    "        total_rewards.append(episode_reward)  # Track total reward for the episode\n",
    "        total_reward += episode_reward  # Update cumulative reward\n",
    "        cumulative_rewards.append(total_reward)  # Add to the list of cumulative rewards\n",
    "\n",
    "        # Optionally, print the total reward for every 100th episode\n",
    "        if (episode + 1) % 100 == 0:\n",
    "            print(f\"Episode {episode + 1}/{episodes}, Total Reward: {episode_reward}, Cumulative Reward: {total_reward}\")\n",
    "\n",
    "    # Return the cumulative rewards for analysis\n",
    "    return cumulative_rewards\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100/1000, Total Reward: -190, Cumulative Reward: -19289\n",
      "Episode 200/1000, Total Reward: -118, Cumulative Reward: -33713\n",
      "Episode 300/1000, Total Reward: -181, Cumulative Reward: -46335\n",
      "Episode 400/1000, Total Reward: -154, Cumulative Reward: -59226\n",
      "Episode 500/1000, Total Reward: -136, Cumulative Reward: -68960\n",
      "Episode 600/1000, Total Reward: -163, Cumulative Reward: -78641\n",
      "Episode 700/1000, Total Reward: -60, Cumulative Reward: -88179\n",
      "Episode 800/1000, Total Reward: 7, Cumulative Reward: -95327\n",
      "Episode 900/1000, Total Reward: 11, Cumulative Reward: -100977\n",
      "Episode 1000/1000, Total Reward: -22, Cumulative Reward: -105970\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the agent and track cumulative rewards\n",
    "alpha = 0.1\n",
    "gamma = 0.9\n",
    "epsilon = 0.1\n",
    "\n",
    "cumulative_rewards = train_agent(alpha, gamma, epsilon)\n",
    "\n",
    "# Plot the cumulative rewards over time\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(episodes), cumulative_rewards, label=f'Alpha={alpha}, Gamma={gamma}, Epsilon={epsilon}')\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Cumulative Reward')\n",
    "plt.title('Cumulative Rewards Over Time During Training')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the grid and how the taxi moves within it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Taxi Grid:\n",
      "D       P\n",
      "         \n",
      "         \n",
      "    T    \n",
      "         \n",
      "\n",
      "\n",
      "\n",
      "Current Taxi Grid:\n",
      "D       P\n",
      "         \n",
      "         \n",
      "  T      \n",
      "         \n",
      "\n",
      "\n",
      "\n",
      "Current Taxi Grid:\n",
      "D       P\n",
      "         \n",
      "         \n",
      "  T      \n",
      "         \n",
      "\n",
      "\n",
      "\n",
      "Current Taxi Grid:\n",
      "D       P\n",
      "         \n",
      "         \n",
      "  T      \n",
      "         \n",
      "\n",
      "\n",
      "\n",
      "Current Taxi Grid:\n",
      "D       P\n",
      "         \n",
      "  T      \n",
      "         \n",
      "         \n",
      "\n",
      "\n",
      "\n",
      "Current Taxi Grid:\n",
      "D       P\n",
      "  T      \n",
      "         \n",
      "         \n",
      "         \n",
      "\n",
      "\n",
      "\n",
      "Current Taxi Grid:\n",
      "D       P\n",
      "         \n",
      "  T      \n",
      "         \n",
      "         \n",
      "\n",
      "\n",
      "\n",
      "Current Taxi Grid:\n",
      "D       P\n",
      "         \n",
      "  T      \n",
      "         \n",
      "         \n",
      "\n",
      "\n",
      "\n",
      "Current Taxi Grid:\n",
      "D       P\n",
      "         \n",
      "    T    \n",
      "         \n",
      "         \n",
      "\n",
      "\n",
      "\n",
      "Current Taxi Grid:\n",
      "D       P\n",
      "         \n",
      "    T    \n",
      "         \n",
      "         \n",
      "\n",
      "\n",
      "\n",
      "Current Taxi Grid:\n",
      "D       P\n",
      "         \n",
      "         \n",
      "    T    \n",
      "         \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "# Create the Taxi environment and unwrap it to access the original Taxi environment\n",
    "env = gym.make(\"Taxi-v3\")\n",
    "env = env.unwrapped  # Unwrap the environment to access the original 'Taxi-v3' environment\n",
    "\n",
    "# Define a function to visualize the current state of the grid\n",
    "def render_taxi_grid(state):\n",
    "    # Decode the state into (taxi_row, taxi_col, passenger_location, destination_location)\n",
    "    taxi_row, taxi_col, passenger_location, destination_location = env.decode(state)\n",
    "    \n",
    "    # Create a 5x5 grid of empty spaces\n",
    "    grid = [[' ' for _ in range(5)] for _ in range(5)]\n",
    "    \n",
    "    # Mark the taxi's position\n",
    "    grid[taxi_row][taxi_col] = 'T'\n",
    "    \n",
    "    # Mark the passenger's position (P) based on passenger location\n",
    "    if passenger_location == 0:  # 0 represents the passenger in the lower-left corner\n",
    "        grid[0][0] = 'P'\n",
    "    elif passenger_location == 1:  # 1 represents the passenger in the lower-right corner\n",
    "        grid[0][4] = 'P'\n",
    "    elif passenger_location == 2:  # 2 represents the passenger in the upper-left corner\n",
    "        grid[4][0] = 'P'\n",
    "    elif passenger_location == 3:  # 3 represents the passenger in the upper-right corner\n",
    "        grid[4][4] = 'P'\n",
    "    \n",
    "    # Mark the destination (D) based on destination location\n",
    "    if destination_location == 0:  # 0 represents the lower-left corner\n",
    "        grid[0][0] = 'D'\n",
    "    elif destination_location == 1:  # 1 represents the lower-right corner\n",
    "        grid[0][4] = 'D'\n",
    "    elif destination_location == 2:  # 2 represents the upper-left corner\n",
    "        grid[4][0] = 'D'\n",
    "    elif destination_location == 3:  # 3 represents the upper-right corner\n",
    "        grid[4][4] = 'D'\n",
    "    \n",
    "    # Print the grid\n",
    "    print(\"\\nCurrent Taxi Grid:\")\n",
    "    for row in grid:\n",
    "        print(\" \".join(row))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Reset the environment to start from the initial state (encoded state)\n",
    "state, info = env.reset()  # We now get a tuple: (state, info)\n",
    "\n",
    "# Render the initial grid\n",
    "render_taxi_grid(state)  # Only pass the state (encoded integer)\n",
    "\n",
    "# Run a simple loop where the taxi takes random actions for 10 steps\n",
    "for step in range(10):\n",
    "    action = env.action_space.sample()  # Sample a random action\n",
    "    state, reward, done, _, _ = env.step(action)  # Perform the action (returns new state)\n",
    "    \n",
    "    # Render the grid after the action\n",
    "    render_taxi_grid(state)\n",
    "    \n",
    "    if done:\n",
    "        print(f\"Episode finished after {step + 1} steps\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the performance with a random policy and a heuristic-based policy. \n",
    "\n",
    "1. Random Policy:\n",
    "The agent chooses actions randomly from the available action space.\n",
    "\n",
    "2. Heuristic-based Policy:\n",
    "This policy uses a simple heuristic to make decisions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing Random Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_policy(env):\n",
    "    state, info = env.reset()  # Reset environment (for gymnasium v0.26+)\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action = env.action_space.sample()  # Randomly select an action\n",
    "        next_state, reward, done, truncated, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        state = next_state\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Implementing Heuristic-based Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic_policy(env):\n",
    "    state, info = env.reset()  # Reset environment (for gymnasium v0.26+)\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        # Decode the current state (state is an integer, so decode it into a more readable format)\n",
    "        taxi_pos, passenger_pos, destination_pos, is_picked_up = env.unwrapped.decode(state)\n",
    "\n",
    "        # Calculate the Manhattan distance to the pickup and dropoff points\n",
    "        if is_picked_up:\n",
    "            target = destination_pos  # Move towards the dropoff location\n",
    "        else:\n",
    "            target = passenger_pos  # Move towards the pickup location\n",
    "        \n",
    "        # Get the current position of the taxi\n",
    "        taxi_row, taxi_col = taxi_pos // 5, taxi_pos % 5\n",
    "        target_row, target_col = target // 5, target % 5\n",
    "\n",
    "        # List all possible actions (assuming 6 directions in Taxi-v3)\n",
    "        possible_actions = env.action_space.n\n",
    "        best_action = None\n",
    "        min_distance = float('inf')\n",
    "\n",
    "        for action in range(possible_actions):\n",
    "            next_state, reward, done, truncated, info = env.step(action)\n",
    "            \n",
    "            # Decode the next state into the taxi position (and other elements)\n",
    "            next_taxi_pos, _, _, _ = env.unwrapped.decode(next_state)\n",
    "            next_row, next_col = next_taxi_pos // 5, next_taxi_pos % 5\n",
    "            distance = abs(next_row - target_row) + abs(next_col - target_col)\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                best_action = action\n",
    "\n",
    "        # Perform the best action\n",
    "        next_state, reward, done, truncated, info = env.step(best_action)\n",
    "        total_reward += reward\n",
    "        state = next_state\n",
    "\n",
    "    return total_reward\n",
    "\n",
    "def evaluate_policy(policy, env, num_episodes=100):\n",
    "    \"\"\"\n",
    "    Evaluate a policy by running it for a number of episodes.\n",
    "    \n",
    "    Args:\n",
    "    - policy: A function that implements the policy to be evaluated.\n",
    "    - env: The environment in which to evaluate the policy.\n",
    "    - num_episodes: The number of episodes to run for evaluation.\n",
    "    \n",
    "    Returns:\n",
    "    - A list of total rewards for each episode.\n",
    "    \"\"\"\n",
    "    rewards = []\n",
    "    for _ in range(num_episodes):\n",
    "        total_reward = policy(env)\n",
    "        rewards.append(total_reward)\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Comparing the Performance of the Three Policies, Plotting the Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Run\u001b[39;00m\n\u001b[0;32m     31\u001b[0m env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTaxi-v3\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Replace with your environment if different\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[43mcompare_policies\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m, in \u001b[0;36mcompare_policies\u001b[1;34m(env, num_episodes)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompare_policies\u001b[39m(env, num_episodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Get the performance for each policy\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     random_rewards \u001b[38;5;241m=\u001b[39m evaluate_policy(random_policy, env, num_episodes)\n\u001b[1;32m----> 9\u001b[0m     heuristic_rewards \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheuristic_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Calculate average rewards for each policy\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     random_avg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(random_rewards)\n",
      "Cell \u001b[1;32mIn[8], line 57\u001b[0m, in \u001b[0;36mevaluate_policy\u001b[1;34m(policy, env, num_episodes)\u001b[0m\n\u001b[0;32m     55\u001b[0m rewards \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_episodes):\n\u001b[1;32m---> 57\u001b[0m     total_reward \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m     rewards\u001b[38;5;241m.\u001b[39mappend(total_reward)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rewards\n",
      "Cell \u001b[1;32mIn[8], line 26\u001b[0m, in \u001b[0;36mheuristic_policy\u001b[1;34m(env)\u001b[0m\n\u001b[0;32m     23\u001b[0m min_distance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(possible_actions):\n\u001b[1;32m---> 26\u001b[0m     next_state, reward, done, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# Decode the next state into the taxi position (and other elements)\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     next_taxi_pos, _, _, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39munwrapped\u001b[38;5;241m.\u001b[39mdecode(next_state)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gymnasium\\wrappers\\common.py:125\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: ActType\n\u001b[0;32m    114\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[ObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    123\u001b[0m \n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gymnasium\\wrappers\\common.py:393\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gymnasium\\core.py:322\u001b[0m, in \u001b[0;36mWrapper.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[0;32m    320\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[0;32m    321\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gymnasium\\wrappers\\common.py:285\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gymnasium\\envs\\toy_text\\taxi.py:290\u001b[0m, in \u001b[0;36mTaxiEnv.step\u001b[1;34m(self, a)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, a):\n\u001b[0;32m    289\u001b[0m     transitions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mP[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms][a]\n\u001b[1;32m--> 290\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[43mcategorical_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtransitions\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnp_random\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    291\u001b[0m     p, s, r, t \u001b[38;5;241m=\u001b[39m transitions[i]\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms \u001b[38;5;241m=\u001b[39m s\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gymnasium\\envs\\toy_text\\utils.py:8\u001b[0m, in \u001b[0;36mcategorical_sample\u001b[1;34m(prob_n, np_random)\u001b[0m\n\u001b[0;32m      6\u001b[0m prob_n \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(prob_n)\n\u001b[0;32m      7\u001b[0m csprob_n \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcumsum(prob_n)\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsprob_n\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp_random\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:1359\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1270\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1271\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[0;32m   1272\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1356\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[0;32m   1357\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1358\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m-> 1359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "\n",
    "\n",
    "def compare_policies(env, num_episodes=5):\n",
    "    # Get the performance for each policy\n",
    "    random_rewards = evaluate_policy(random_policy, env, num_episodes)\n",
    "    heuristic_rewards = evaluate_policy(heuristic_policy, env, num_episodes)\n",
    "    \n",
    "    # Calculate average rewards for each policy\n",
    "    random_avg = np.mean(random_rewards)\n",
    "    heuristic_avg = np.mean(heuristic_rewards)\n",
    "    \n",
    "    # Create a bar plot to compare the average rewards\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    policies = ['Random Policy', 'Heuristic Policy']\n",
    "    avg_rewards = [random_avg, heuristic_avg]\n",
    "    \n",
    "    plt.bar(policies, avg_rewards, color=['blue', 'green'])\n",
    "    plt.title(f'Policy Comparison: Average Reward Over {num_episodes} Episodes')\n",
    "    plt.xlabel('Policy')\n",
    "    plt.ylabel('Average Reward')\n",
    "    plt.show()\n",
    "\n",
    "    # Print average rewards for each policy\n",
    "    print(f'Average reward (Random Policy): {random_avg}')\n",
    "    print(f'Average reward (Heuristic Policy): {heuristic_avg}')\n",
    "\n",
    "# Run\n",
    "env = gym.make('Taxi-v3')  # Replace with your environment if different\n",
    "compare_policies(env, num_episodes=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the RL agent on the Taxi-v3 environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0/1000, Total Reward: -271\n",
      "Episode 100/1000, Total Reward: -118\n",
      "Episode 200/1000, Total Reward: -18\n",
      "Episode 300/1000, Total Reward: 9\n",
      "Episode 400/1000, Total Reward: 3\n",
      "Episode 500/1000, Total Reward: 5\n",
      "Episode 600/1000, Total Reward: -5\n",
      "Episode 700/1000, Total Reward: -13\n",
      "Episode 800/1000, Total Reward: -2\n",
      "Episode 900/1000, Total Reward: 6\n",
      "Average reward over 10 episodes: 7.8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the Taxi-v3 environment\n",
    "env = gym.make('Taxi-v3')\n",
    "\n",
    "# Initialize the Q-table with zeros (state x action)\n",
    "# State space has 500 states, action space has 6 actions (0-5)\n",
    "Q = np.zeros([env.observation_space.n, env.action_space.n])\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.8        # Alpha: How much new information overrides old information\n",
    "discount_factor = 0.95     # Gamma: Discount factor for future rewards\n",
    "epsilon = 0.1              # Epsilon: Probability of choosing a random action (exploration)\n",
    "num_episodes = 1000        # Total number of training episodes\n",
    "max_steps_per_episode = 100  # Max steps in an episode\n",
    "\n",
    "# Function to choose an action based on epsilon-greedy policy\n",
    "def epsilon_greedy_policy(state, epsilon):\n",
    "    if np.random.uniform(0, 1) < epsilon:\n",
    "        return env.action_space.sample()  # Explore: choose a random action\n",
    "    else:\n",
    "        return np.argmax(Q[state])        # Exploit: choose the action with the highest Q-value\n",
    "\n",
    "# Training loop\n",
    "for episode in range(num_episodes):\n",
    "    state, _ = env.reset()  # Reset the environment at the start of each episode\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    for step in range(max_steps_per_episode):\n",
    "        action = epsilon_greedy_policy(state, epsilon)\n",
    "        next_state, reward, done, _, _ = env.step(action)  # Take the action and observe the result\n",
    "\n",
    "        # Update the Q-table using the Q-learning update rule\n",
    "        Q[state, action] = Q[state, action] + learning_rate * (reward + discount_factor * np.max(Q[next_state]) - Q[state, action])\n",
    "        \n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # Optional: Print episode info every 100th episode\n",
    "    if episode % 100 == 0:\n",
    "        print(f\"Episode {episode}/{num_episodes}, Total Reward: {total_reward}\")\n",
    "\n",
    "# After training, evaluate the agent\n",
    "def evaluate_agent(num_episodes=10):\n",
    "    total_rewards = 0\n",
    "    for _ in range(num_episodes):\n",
    "        state, _ = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        \n",
    "        while not done:\n",
    "            action = np.argmax(Q[state])  # Choose the best action based on Q-table (exploitation)\n",
    "            state, reward, done, _, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "        \n",
    "        total_rewards += total_reward\n",
    "    \n",
    "    avg_reward = total_rewards / num_episodes\n",
    "    print(f\"Average reward over {num_episodes} episodes: {avg_reward}\")\n",
    "    return avg_reward\n",
    "\n",
    "# Evaluate the trained agent\n",
    "evaluate_agent(10)\n",
    "\n",
    "# Plot Q-table heatmap (Optional for visualization)\n",
    "plt.imshow(Q, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('Q-table Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
