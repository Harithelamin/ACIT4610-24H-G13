{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACIT 4610, Portfolio-2024\n",
      "\n",
      "Group-13\n",
      "\n",
      "participate: Harith Elamin Thomas Nygaard\n"
     ]
    }
   ],
   "source": [
    "print('ACIT 4610, Portfolio-2024')\n",
    "print('\\nGroup-13')\n",
    "print('\\nparticipate: Harith Elamin', 'Thomas Nygaard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools and Libraries:\n",
      "\n",
      "1- Python 3.\n",
      "\n",
      "2- OpenAI Gym for the environment.\n",
      "\n",
      "3- Deep to use Genetic Programming, implement an evolutionary algorithms.\n",
      "\n",
      "4- NumPy for numerical computations.\n",
      "\n",
      "5- pandas for data manipulation and analysis.\n",
      "\n",
      "6- requests for the process of sending and receiving data from websites.\n",
      "\n",
      "7- Matplotlib for plotting results.\n",
      "\n",
      "8- TensorFlow/PyTorch for more advanced RL algorithms like DQN.\n",
      "\n",
      "9- pymoo for for multi-objective optimization algorithms.\n",
      "\n",
      "10-Keras for the convenience of mathematical calculations\n",
      "about-time==4.2.1\n",
      "alive-progress==3.1.5\n",
      "asttokens==2.4.1\n",
      "autograd==1.7.0\n",
      "beautifulsoup4==4.12.3\n",
      "certifi==2024.8.30\n",
      "charset-normalizer==3.4.0\n",
      "cloudpickle==3.1.0\n",
      "cma==3.2.2\n",
      "colorama==0.4.6\n",
      "comm==0.2.2\n",
      "contourpy==1.3.0\n",
      "cycler==0.12.1\n",
      "deap==1.4.1\n",
      "debugpy==1.8.7\n",
      "decorator==5.1.1\n",
      "Deprecated==1.2.14\n",
      "dill==0.3.9\n",
      "executing==2.1.0\n",
      "Farama-Notifications==0.0.4\n",
      "fonttools==4.54.1\n",
      "frozendict==2.4.6\n",
      "grapheme==0.6.0\n",
      "gym==0.26.2\n",
      "gym-notices==0.0.8\n",
      "gymnasium==1.0.0\n",
      "html5lib==1.1\n",
      "idna==3.10\n",
      "ipykernel==6.29.5\n",
      "ipython==8.28.0\n",
      "jedi==0.19.1\n",
      "joblib==1.4.2\n",
      "jupyter_client==8.6.3\n",
      "jupyter_core==5.7.2\n",
      "kiwisolver==1.4.7\n",
      "lxml==5.3.0\n",
      "matplotlib==3.9.2\n",
      "matplotlib-inline==0.1.7\n",
      "multitasking==0.0.11\n",
      "nest-asyncio==1.6.0\n",
      "numpy==2.1.2\n",
      "packaging==24.1\n",
      "pandas==2.2.3\n",
      "parso==0.8.4\n",
      "peewee==3.17.7\n",
      "pillow==11.0.0\n",
      "platformdirs==4.3.6\n",
      "prompt_toolkit==3.0.48\n",
      "psutil==6.1.0\n",
      "pure_eval==0.2.3\n",
      "Pygments==2.18.0\n",
      "pymoo==0.6.1.3\n",
      "pyparsing==3.2.0\n",
      "python-dateutil==2.9.0.post0\n",
      "pytz==2024.2\n",
      "pywin32==308\n",
      "pyzmq==26.2.0\n",
      "requests==2.32.3\n",
      "scikit-fuzzy==0.5.0\n",
      "scikit-learn==1.5.2\n",
      "scipy==1.14.1\n",
      "six==1.16.0\n",
      "soupsieve==2.6\n",
      "stack-data==0.6.3\n",
      "threadpoolctl==3.5.0\n",
      "tornado==6.4.1\n",
      "traitlets==5.14.3\n",
      "typing_extensions==4.12.2\n",
      "tzdata==2024.2\n",
      "urllib3==2.2.3\n",
      "wcwidth==0.2.13\n",
      "webencodings==0.5.1\n",
      "wrapt==1.16.0\n",
      "yfinance==0.2.48\n",
      "Requirement already satisfied: gym in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.26.2)\n",
      "Collecting pygame\n",
      "  Using cached pygame-2.6.1-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.1.2)\n",
      "System version 3.13.0 (tags/v3.13.0:60403a5, Oct  7 2024, 09:38:07) [MSC v.1941 64 bit (AMD64)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for tensorflow\n"
     ]
    }
   ],
   "source": [
    "print('Tools and Libraries:')\n",
    "print('\\n1- Python 3.')\n",
    "print('\\n2- OpenAI Gym for the environment.')\n",
    "print('\\n3- Deep to use Genetic Programming, implement an evolutionary algorithms.')\n",
    "print('\\n4- NumPy for numerical computations.')\n",
    "print('\\n5- pandas for data manipulation and analysis.')\n",
    "print('\\n6- requests for the process of sending and receiving data from websites.')\n",
    "print('\\n7- Matplotlib for plotting results.')\n",
    "print('\\n8- TensorFlow/PyTorch for more advanced RL algorithms like DQN.')\n",
    "print('\\n9- pymoo for for multi-objective optimization algorithms.')\n",
    "print('\\n10-Keras for the convenience of mathematical calculations')\n",
    "\n",
    "!pip3 freeze\n",
    "!pip3 install gym pygame numpy tensorflow keras openAi matplotlib requests pandas gym deap pymoo\n",
    "\n",
    "\n",
    "import sys\n",
    "print('System version',sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 4: Solving a Real-World Problem Using Reinforcement Learning\n",
    "\n",
    "Overview \n",
    "This lab exercise aims to apply reinforcement learning techniques to solve a real-world \n",
    "problem. Students will use a publicly available dataset to train an RL agent, evaluate its \n",
    "performance, and optimize it to achieve the best possible outcome. \n",
    "\n",
    "Problem Statement: \n",
    "Autonomous Taxi Navigation \n",
    "You will develop an autonomous taxi driver who picks up passengers and drops them off at \n",
    "their destinations in the shortest possible time. The environment is a grid-based city, and the \n",
    "taxi must navigate to specific locations while avoiding obstacles, optimizing routes, and \n",
    "maximizing the efficiency of passenger pickups and drop-offs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: \n",
    "In order to utilize the Taxi-v3 environment available in the OpenAI Gym we have to interact with Taxi-v3 Environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "# Create the Taxi environment\n",
    "env = gym.make('Taxi-v3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks: \n",
    "1. Understanding the Environment:\n",
    "A. Explore the Taxi-v3 environment.\n",
    "B. Understand the state space, action space, and reward system. \n",
    "C. Visualize the grid and how the taxi moves within it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial State:\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 5, Reward: -10, Next State: 413\n",
      "Action: 5, Reward: -10, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 1, Reward: -1, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 4, Reward: -10, Next State: 113\n",
      "Action: 0, Reward: -1, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 4, Reward: -10, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 5, Reward: -10, Next State: 213\n",
      "Action: 4, Reward: -10, Next State: 213\n",
      "Action: 5, Reward: -10, Next State: 213\n",
      "Action: 5, Reward: -10, Next State: 213\n",
      "Action: 4, Reward: -10, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 1, Reward: -1, Next State: 113\n",
      "Action: 5, Reward: -10, Next State: 113\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 0, Reward: -1, Next State: 113\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 5, Reward: -10, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 5, Reward: -10, Next State: 113\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 4, Reward: -10, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 0, Reward: -1, Next State: 233\n",
      "Action: 4, Reward: -10, Next State: 233\n",
      "Action: 4, Reward: -10, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 4, Reward: -10, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 5, Reward: -10, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 5, Reward: -10, Next State: 213\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 2, Reward: -1, Next State: 413\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 2, Reward: -1, Next State: 413\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 2, Reward: -1, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 1, Reward: -1, Next State: 133\n",
      "Action: 0, Reward: -1, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 1, Reward: -1, Next State: 133\n",
      "Action: 0, Reward: -1, Next State: 233\n",
      "Action: 4, Reward: -10, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 0, Reward: -1, Next State: 373\n",
      "Action: 4, Reward: -10, Next State: 373\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 4, Reward: -10, Next State: 373\n",
      "Action: 1, Reward: -1, Next State: 273\n",
      "Action: 0, Reward: -1, Next State: 373\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 5, Reward: -10, Next State: 393\n",
      "Action: 4, Reward: -10, Next State: 393\n",
      "Action: 5, Reward: -10, Next State: 393\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 0, Reward: -1, Next State: 493\n",
      "Action: 5, Reward: -10, Next State: 493\n",
      "Action: 0, Reward: -1, Next State: 493\n",
      "Action: 1, Reward: -1, Next State: 393\n",
      "Action: 4, Reward: -10, Next State: 393\n",
      "Action: 4, Reward: -10, Next State: 393\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 4, Reward: -10, Next State: 393\n",
      "Action: 0, Reward: -1, Next State: 493\n",
      "Action: 2, Reward: -1, Next State: 493\n",
      "Action: 0, Reward: -1, Next State: 493\n",
      "Action: 3, Reward: -1, Next State: 473\n",
      "Action: 1, Reward: -1, Next State: 373\n",
      "Action: 5, Reward: -10, Next State: 373\n",
      "Action: 5, Reward: -10, Next State: 373\n",
      "Action: 1, Reward: -1, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 0, Reward: -1, Next State: 373\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 1, Reward: -1, Next State: 293\n",
      "Action: 0, Reward: -1, Next State: 393\n",
      "Action: 4, Reward: -10, Next State: 393\n",
      "Action: 0, Reward: -1, Next State: 493\n",
      "Action: 4, Reward: -10, Next State: 493\n",
      "Action: 3, Reward: -1, Next State: 473\n",
      "Action: 1, Reward: -1, Next State: 373\n",
      "Action: 1, Reward: -1, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 0, Reward: -1, Next State: 373\n",
      "Action: 5, Reward: -10, Next State: 373\n",
      "Action: 4, Reward: -10, Next State: 373\n",
      "Action: 5, Reward: -10, Next State: 373\n",
      "Action: 5, Reward: -10, Next State: 373\n",
      "Action: 4, Reward: -10, Next State: 373\n",
      "Action: 4, Reward: -10, Next State: 373\n",
      "Action: 1, Reward: -1, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 4, Reward: -10, Next State: 53\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 2, Reward: -1, Next State: 173\n",
      "Action: 0, Reward: -1, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 2, Reward: -1, Next State: 73\n",
      "Action: 5, Reward: -10, Next State: 73\n",
      "Action: 0, Reward: -1, Next State: 173\n",
      "Action: 0, Reward: -1, Next State: 273\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 5, Reward: -10, Next State: 293\n",
      "Action: 1, Reward: -1, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 1, Reward: -1, Next State: 193\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 4, Reward: -10, Next State: 93\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 3, Reward: -1, Next State: 73\n",
      "Action: 1, Reward: -1, Next State: 73\n",
      "Action: 0, Reward: -1, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 0, Reward: -1, Next State: 393\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 4, Reward: -10, Next State: 373\n",
      "Action: 0, Reward: -1, Next State: 473\n",
      "Action: 0, Reward: -1, Next State: 473\n",
      "Action: 5, Reward: -10, Next State: 473\n",
      "Action: 1, Reward: -1, Next State: 373\n",
      "Action: 0, Reward: -1, Next State: 473\n",
      "Action: 2, Reward: -1, Next State: 493\n",
      "Action: 5, Reward: -10, Next State: 493\n",
      "Action: 4, Reward: -10, Next State: 493\n",
      "Action: 0, Reward: -1, Next State: 493\n",
      "Action: 2, Reward: -1, Next State: 493\n",
      "Action: 5, Reward: -10, Next State: 493\n",
      "Action: 0, Reward: -1, Next State: 493\n",
      "Action: 1, Reward: -1, Next State: 393\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 0, Reward: -1, Next State: 473\n",
      "Action: 3, Reward: -1, Next State: 473\n",
      "Action: 2, Reward: -1, Next State: 493\n",
      "Action: 0, Reward: -1, Next State: 493\n",
      "Action: 5, Reward: -10, Next State: 493\n",
      "Action: 5, Reward: -10, Next State: 493\n",
      "Action: 1, Reward: -1, Next State: 393\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 1, Reward: -1, Next State: 273\n",
      "Action: 0, Reward: -1, Next State: 373\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 1, Reward: -1, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 1, Reward: -1, Next State: 73\n",
      "Action: 1, Reward: -1, Next State: 73\n",
      "Action: 4, Reward: -10, Next State: 73\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 4, Reward: -10, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 4, Reward: -10, Next State: 53\n",
      "Action: 4, Reward: -10, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 2, Reward: -1, Next State: 173\n",
      "Action: 0, Reward: -1, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 2, Reward: -1, Next State: 173\n",
      "Action: 1, Reward: -1, Next State: 73\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 2, Reward: -1, Next State: 73\n",
      "Action: 4, Reward: -10, Next State: 73\n",
      "Action: 5, Reward: -10, Next State: 73\n",
      "Action: 5, Reward: -10, Next State: 73\n",
      "Action: 4, Reward: -10, Next State: 73\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 3, Reward: -1, Next State: 73\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 2, Reward: -1, Next State: 73\n",
      "Action: 5, Reward: -10, Next State: 73\n",
      "Action: 4, Reward: -10, Next State: 73\n",
      "Action: 4, Reward: -10, Next State: 73\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 5, Reward: -10, Next State: 293\n",
      "Action: 3, Reward: -1, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 4, Reward: -10, Next State: 173\n",
      "Action: 0, Reward: -1, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 1, Reward: -1, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 1, Reward: -1, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 1, Reward: -1, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 4, Reward: -10, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 4, Reward: -10, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 1, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 1, Reward: -1, Next State: 133\n",
      "Action: 5, Reward: -10, Next State: 133\n",
      "Action: 1, Reward: -1, Next State: 33\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 4, Reward: -10, Next State: 33\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 1, Reward: -1, Next State: 33\n",
      "Action: 5, Reward: -10, Next State: 33\n",
      "Action: 1, Reward: -1, Next State: 33\n",
      "Action: 4, Reward: -10, Next State: 33\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 5, Reward: -10, Next State: 13\n",
      "Action: 0, Reward: -1, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 5, Reward: -10, Next State: 113\n",
      "Action: 4, Reward: -10, Next State: 113\n",
      "Action: 4, Reward: -10, Next State: 113\n",
      "Action: 5, Reward: -10, Next State: 113\n",
      "Action: 0, Reward: -1, Next State: 213\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 5, Reward: -10, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 4, Reward: -10, Next State: 213\n",
      "Action: 1, Reward: -1, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 5, Reward: -10, Next State: 33\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 5, Reward: -10, Next State: 33\n",
      "Action: 0, Reward: -1, Next State: 133\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 4, Reward: -10, Next State: 133\n",
      "Action: 1, Reward: -1, Next State: 33\n",
      "Action: 5, Reward: -10, Next State: 33\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 4, Reward: -10, Next State: 13\n",
      "Action: 0, Reward: -1, Next State: 113\n",
      "Action: 4, Reward: -10, Next State: 113\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 4, Reward: -10, Next State: 133\n",
      "Action: 0, Reward: -1, Next State: 233\n",
      "Action: 1, Reward: -1, Next State: 133\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 5, Reward: -10, Next State: 133\n",
      "Action: 1, Reward: -1, Next State: 33\n",
      "Action: 5, Reward: -10, Next State: 33\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 4, Reward: -10, Next State: 33\n",
      "Action: 5, Reward: -10, Next State: 33\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 4, Reward: -10, Next State: 33\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 0, Reward: -1, Next State: 133\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 4, Reward: -10, Next State: 13\n",
      "Action: 5, Reward: -10, Next State: 13\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 5, Reward: -10, Next State: 13\n",
      "Action: 0, Reward: -1, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 5, Reward: -10, Next State: 113\n",
      "Action: 5, Reward: -10, Next State: 113\n",
      "Action: 5, Reward: -10, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 5, Reward: -10, Next State: 13\n",
      "Action: 4, Reward: -10, Next State: 13\n",
      "Action: 5, Reward: -10, Next State: 13\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 0, Reward: -1, Next State: 133\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 4, Reward: -10, Next State: 113\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 4, Reward: -10, Next State: 113\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 4, Reward: -10, Next State: 13\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 4, Reward: -10, Next State: 33\n",
      "Action: 4, Reward: -10, Next State: 33\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 1, Reward: -1, Next State: 33\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 0, Reward: -1, Next State: 133\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 0, Reward: -1, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 4, Reward: -10, Next State: 213\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 4, Reward: -10, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 4, Reward: -10, Next State: 453\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 1, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 5, Reward: -10, Next State: 433\n",
      "Action: 4, Reward: -10, Next State: 433\n",
      "Action: 5, Reward: -10, Next State: 433\n",
      "Action: 1, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 4, Reward: -10, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 5, Reward: -10, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 1, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 1, Reward: -1, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 5, Reward: -10, Next State: 433\n",
      "Action: 1, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 4, Reward: -10, Next State: 433\n",
      "Action: 1, Reward: -1, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 4, Reward: -10, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 5, Reward: -10, Next State: 213\n",
      "Action: 5, Reward: -10, Next State: 213\n",
      "Action: 5, Reward: -10, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 2, Reward: -1, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 5, Reward: -10, Next State: 213\n",
      "Action: 5, Reward: -10, Next State: 213\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 4, Reward: -10, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 4, Reward: -10, Next State: 233\n",
      "Action: 5, Reward: -10, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 1, Reward: -1, Next State: 113\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 0, Reward: -1, Next State: 113\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 0, Reward: -1, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 4, Reward: -10, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 0, Reward: -1, Next State: 273\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 5, Reward: -10, Next State: 293\n",
      "Action: 5, Reward: -10, Next State: 293\n",
      "Action: 0, Reward: -1, Next State: 393\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 1, Reward: -1, Next State: 273\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 5, Reward: -10, Next State: 293\n",
      "Action: 5, Reward: -10, Next State: 293\n",
      "Action: 1, Reward: -1, Next State: 193\n",
      "Action: 5, Reward: -10, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 0, Reward: -1, Next State: 393\n",
      "Action: 1, Reward: -1, Next State: 293\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 1, Reward: -1, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 3, Reward: -1, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 0, Reward: -1, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 1, Reward: -1, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 4, Reward: -10, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 4, Reward: -10, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 3, Reward: -1, Next State: 173\n",
      "Action: 0, Reward: -1, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 4, Reward: -10, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 1, Reward: -1, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 5, Reward: -10, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 0, Reward: -1, Next State: 393\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 5, Reward: -10, Next State: 393\n",
      "Action: 4, Reward: -10, Next State: 393\n",
      "Action: 5, Reward: -10, Next State: 393\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 4, Reward: -10, Next State: 393\n",
      "Action: 1, Reward: -1, Next State: 293\n",
      "Action: 1, Reward: -1, Next State: 193\n",
      "Action: 5, Reward: -10, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 1, Reward: -1, Next State: 193\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 3, Reward: -1, Next State: 73\n",
      "Action: 0, Reward: -1, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 4, Reward: -10, Next State: 173\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 4, Reward: -10, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 4, Reward: -10, Next State: 453\n",
      "Action: 4, Reward: -10, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 1, Reward: -1, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 1, Reward: -1, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 0, Reward: -1, Next State: 373\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 5, Reward: -10, Next State: 373\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 1, Reward: -1, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 0, Reward: -1, Next State: 373\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 0, Reward: -1, Next State: 473\n",
      "Action: 5, Reward: -10, Next State: 473\n",
      "Action: 1, Reward: -1, Next State: 373\n",
      "Action: 0, Reward: -1, Next State: 473\n",
      "Action: 2, Reward: -1, Next State: 493\n",
      "Action: 1, Reward: -1, Next State: 393\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 0, Reward: -1, Next State: 493\n",
      "Action: 3, Reward: -1, Next State: 473\n",
      "Action: 2, Reward: -1, Next State: 493\n",
      "Action: 1, Reward: -1, Next State: 393\n",
      "Action: 5, Reward: -10, Next State: 393\n",
      "Action: 1, Reward: -1, Next State: 293\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 1, Reward: -1, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 4, Reward: -10, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 3, Reward: -1, Next State: 73\n",
      "Action: 5, Reward: -10, Next State: 73\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 1, Reward: -1, Next State: 133\n",
      "Action: 0, Reward: -1, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 1, Reward: -1, Next State: 113\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 4, Reward: -10, Next State: 13\n",
      "Action: 5, Reward: -10, Next State: 13\n",
      "Action: 0, Reward: -1, Next State: 113\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 4, Reward: -10, Next State: 133\n",
      "Action: 4, Reward: -10, Next State: 133\n",
      "Action: 0, Reward: -1, Next State: 233\n",
      "Action: 4, Reward: -10, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 5, Reward: -10, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 5, Reward: -10, Next State: 233\n",
      "Action: 4, Reward: -10, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 5, Reward: -10, Next State: 233\n",
      "Action: 4, Reward: -10, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 5, Reward: -10, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 4, Reward: -10, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 4, Reward: -10, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 2, Reward: -1, Next State: 173\n",
      "Action: 0, Reward: -1, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 0, Reward: -1, Next State: 273\n",
      "Action: 0, Reward: -1, Next State: 373\n",
      "Action: 5, Reward: -10, Next State: 373\n",
      "Action: 1, Reward: -1, Next State: 273\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 0, Reward: -1, Next State: 393\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 1, Reward: -1, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 1, Reward: -1, Next State: 73\n",
      "Action: 4, Reward: -10, Next State: 73\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 2, Reward: -1, Next State: 73\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 3, Reward: -1, Next State: 73\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 5, Reward: -10, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 3, Reward: -1, Next State: 173\n",
      "Action: 4, Reward: -10, Next State: 173\n",
      "Action: 0, Reward: -1, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 1, Reward: -1, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 5, Reward: -10, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 5, Reward: -10, Next State: 193\n",
      "Action: 3, Reward: -1, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 4, Reward: -10, Next State: 173\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 4, Reward: -10, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 4, Reward: -10, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 0, Reward: -1, Next State: 373\n",
      "Action: 1, Reward: -1, Next State: 273\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 0, Reward: -1, Next State: 393\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 1, Reward: -1, Next State: 273\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 3, Reward: -1, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 2, Reward: -1, Next State: 73\n",
      "Action: 4, Reward: -10, Next State: 73\n",
      "Action: 0, Reward: -1, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 4, Reward: -10, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 3, Reward: -1, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 1, Reward: -1, Next State: 193\n",
      "Action: 3, Reward: -1, Next State: 173\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 0, Reward: -1, Next State: 393\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 5, Reward: -10, Next State: 393\n",
      "Action: 5, Reward: -10, Next State: 393\n",
      "Action: 1, Reward: -1, Next State: 293\n",
      "Action: 3, Reward: -1, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 4, Reward: -10, Next State: 173\n",
      "Action: 4, Reward: -10, Next State: 173\n",
      "Action: 0, Reward: -1, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 4, Reward: -10, Next State: 173\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 4, Reward: -10, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 2, Reward: -1, Next State: 73\n",
      "Action: 4, Reward: -10, Next State: 73\n",
      "Action: 4, Reward: -10, Next State: 73\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 3, Reward: -1, Next State: 173\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 2, Reward: -1, Next State: 173\n",
      "Action: 4, Reward: -10, Next State: 173\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 3, Reward: -1, Next State: 173\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 2, Reward: -1, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 5, Reward: -10, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 1, Reward: -1, Next State: 193\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 3, Reward: -1, Next State: 73\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 2, Reward: -1, Next State: 73\n",
      "Action: 1, Reward: -1, Next State: 73\n",
      "Action: 1, Reward: -1, Next State: 73\n",
      "Action: 0, Reward: -1, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 4, Reward: -10, Next State: 53\n",
      "Action: 2, Reward: -1, Next State: 73\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 3, Reward: -1, Next State: 73\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 1, Reward: -1, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 5, Reward: -10, Next State: 93\n",
      "Action: 3, Reward: -1, Next State: 73\n",
      "Action: 0, Reward: -1, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 4, Reward: -10, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 4, Reward: -10, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 4, Reward: -10, Next State: 433\n",
      "Action: 1, Reward: -1, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 4, Reward: -10, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 5, Reward: -10, Next State: 433\n",
      "Action: 1, Reward: -1, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 5, Reward: -10, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 3, Reward: -1, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 4, Reward: -10, Next State: 53\n",
      "Action: 4, Reward: -10, Next State: 53\n",
      "Action: 3, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 2, Reward: -1, Next State: 73\n",
      "Action: 0, Reward: -1, Next State: 173\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 5, Reward: -10, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 1, Reward: -1, Next State: 133\n",
      "Action: 5, Reward: -10, Next State: 133\n",
      "Action: 4, Reward: -10, Next State: 133\n",
      "Action: 5, Reward: -10, Next State: 133\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 1, Reward: -1, Next State: 33\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 4, Reward: -10, Next State: 13\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 1, Reward: -1, Next State: 33\n",
      "Action: 5, Reward: -10, Next State: 33\n",
      "Action: 0, Reward: -1, Next State: 133\n",
      "Action: 1, Reward: -1, Next State: 33\n",
      "Action: 2, Reward: -1, Next State: 33\n",
      "Action: 4, Reward: -10, Next State: 33\n",
      "Action: 5, Reward: -10, Next State: 33\n",
      "Action: 4, Reward: -10, Next State: 33\n",
      "Action: 4, Reward: -10, Next State: 33\n",
      "Action: 4, Reward: -10, Next State: 33\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 4, Reward: -10, Next State: 13\n",
      "Action: 5, Reward: -10, Next State: 13\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 3, Reward: -1, Next State: 13\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 5, Reward: -10, Next State: 13\n",
      "Action: 0, Reward: -1, Next State: 113\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 4, Reward: -10, Next State: 133\n",
      "Action: 4, Reward: -10, Next State: 133\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 0, Reward: -1, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 1, Reward: -1, Next State: 113\n",
      "Action: 0, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 2, Reward: -1, Next State: 413\n",
      "Action: 2, Reward: -1, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 2, Reward: -1, Next State: 413\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 5, Reward: -10, Next State: 413\n",
      "Action: 2, Reward: -1, Next State: 413\n",
      "Action: 5, Reward: -10, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 5, Reward: -10, Next State: 413\n",
      "Action: 5, Reward: -10, Next State: 413\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 5, Reward: -10, Next State: 413\n",
      "Action: 2, Reward: -1, Next State: 413\n",
      "Action: 2, Reward: -1, Next State: 413\n",
      "Action: 2, Reward: -1, Next State: 413\n",
      "Action: 3, Reward: -1, Next State: 413\n",
      "Action: 5, Reward: -10, Next State: 413\n",
      "Action: 2, Reward: -1, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 2, Reward: -1, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 4, Reward: -10, Next State: 413\n",
      "Action: 2, Reward: -1, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 4, Reward: -10, Next State: 213\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 4, Reward: -10, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 1, Reward: -1, Next State: 133\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 5, Reward: -10, Next State: 133\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 4, Reward: -10, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 0, Reward: -1, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 5, Reward: -10, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 1, Reward: -1, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 3, Reward: -1, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 1, Reward: -1, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 5, Reward: -10, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 4, Reward: -10, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 1, Reward: -1, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 1, Reward: -1, Next State: 333\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 4, Reward: -10, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 4, Reward: -10, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 4, Reward: -10, Next State: 433\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 1, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 4, Reward: -10, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 4, Reward: -10, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 1, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 4, Reward: -10, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 4, Reward: -10, Next State: 453\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 4, Reward: -10, Next State: 453\n",
      "Action: 4, Reward: -10, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 5, Reward: -10, Next State: 433\n",
      "Action: 1, Reward: -1, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 5, Reward: -10, Next State: 293\n",
      "Action: 5, Reward: -10, Next State: 293\n",
      "Action: 3, Reward: -1, Next State: 273\n",
      "Action: 0, Reward: -1, Next State: 373\n",
      "Action: 1, Reward: -1, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 4, Reward: -10, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 4, Reward: -10, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 4, Reward: -10, Next State: 433\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 1, Reward: -1, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 4, Reward: -10, Next State: 233\n",
      "Action: 5, Reward: -10, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 1, Reward: -1, Next State: 113\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 0, Reward: -1, Next State: 213\n",
      "Action: 5, Reward: -10, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 5, Reward: -10, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 1, Reward: -1, Next State: 333\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 5, Reward: -10, Next State: 433\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 1, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 0, Reward: -1, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 5, Reward: -10, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 2, Reward: -1, Next State: 313\n",
      "Action: 0, Reward: -1, Next State: 413\n",
      "Action: 1, Reward: -1, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 4, Reward: -10, Next State: 313\n",
      "Action: 5, Reward: -10, Next State: 313\n",
      "Action: 3, Reward: -1, Next State: 313\n",
      "Action: 1, Reward: -1, Next State: 213\n",
      "Action: 4, Reward: -10, Next State: 213\n",
      "Action: 4, Reward: -10, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 1, Reward: -1, Next State: 113\n",
      "Action: 4, Reward: -10, Next State: 113\n",
      "Action: 0, Reward: -1, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 1, Reward: -1, Next State: 73\n",
      "Action: 5, Reward: -10, Next State: 73\n",
      "Action: 5, Reward: -10, Next State: 73\n",
      "Action: 1, Reward: -1, Next State: 73\n",
      "Action: 0, Reward: -1, Next State: 173\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 2, Reward: -1, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 0, Reward: -1, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 2, Reward: -1, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 5, Reward: -10, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 0, Reward: -1, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 4, Reward: -10, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 4, Reward: -10, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 1, Reward: -1, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 4, Reward: -10, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 5, Reward: -10, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 4, Reward: -10, Next State: 433\n",
      "Action: 2, Reward: -1, Next State: 453\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 5, Reward: -10, Next State: 453\n",
      "Action: 4, Reward: -10, Next State: 453\n",
      "Action: 1, Reward: -1, Next State: 353\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 0, Reward: -1, Next State: 453\n",
      "Action: 3, Reward: -1, Next State: 433\n",
      "Action: 5, Reward: -10, Next State: 433\n",
      "Action: 1, Reward: -1, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 4, Reward: -10, Next State: 433\n",
      "Action: 0, Reward: -1, Next State: 433\n",
      "Action: 4, Reward: -10, Next State: 433\n",
      "Action: 1, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 4, Reward: -10, Next State: 333\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 3, Reward: -1, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 5, Reward: -10, Next State: 233\n",
      "Action: 5, Reward: -10, Next State: 233\n",
      "Action: 2, Reward: -1, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 2, Reward: -1, Next State: 173\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 5, Reward: -10, Next State: 193\n",
      "Action: 5, Reward: -10, Next State: 193\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 3, Reward: -1, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 2, Reward: -1, Next State: 173\n",
      "Action: 0, Reward: -1, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 1, Reward: -1, Next State: 193\n",
      "Action: 3, Reward: -1, Next State: 173\n",
      "Action: 1, Reward: -1, Next State: 73\n",
      "Action: 1, Reward: -1, Next State: 73\n",
      "Action: 0, Reward: -1, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 5, Reward: -10, Next State: 173\n",
      "Action: 0, Reward: -1, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 1, Reward: -1, Next State: 173\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 5, Reward: -10, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 5, Reward: -10, Next State: 293\n",
      "Action: 3, Reward: -1, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 0, Reward: -1, Next State: 373\n",
      "Action: 4, Reward: -10, Next State: 373\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 5, Reward: -10, Next State: 373\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 1, Reward: -1, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 3, Reward: -1, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 5, Reward: -10, Next State: 333\n",
      "Action: 1, Reward: -1, Next State: 233\n",
      "Action: 1, Reward: -1, Next State: 133\n",
      "Action: 4, Reward: -10, Next State: 133\n",
      "Action: 4, Reward: -10, Next State: 133\n",
      "Action: 1, Reward: -1, Next State: 33\n",
      "Action: 1, Reward: -1, Next State: 33\n",
      "Action: 5, Reward: -10, Next State: 33\n",
      "Action: 0, Reward: -1, Next State: 133\n",
      "Action: 0, Reward: -1, Next State: 233\n",
      "Action: 5, Reward: -10, Next State: 233\n",
      "Action: 1, Reward: -1, Next State: 133\n",
      "Action: 4, Reward: -10, Next State: 133\n",
      "Action: 4, Reward: -10, Next State: 133\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 5, Reward: -10, Next State: 113\n",
      "Action: 5, Reward: -10, Next State: 113\n",
      "Action: 5, Reward: -10, Next State: 113\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 0, Reward: -1, Next State: 113\n",
      "Action: 5, Reward: -10, Next State: 113\n",
      "Action: 3, Reward: -1, Next State: 113\n",
      "Action: 1, Reward: -1, Next State: 13\n",
      "Action: 4, Reward: -10, Next State: 13\n",
      "Action: 0, Reward: -1, Next State: 113\n",
      "Action: 5, Reward: -10, Next State: 113\n",
      "Action: 2, Reward: -1, Next State: 133\n",
      "Action: 0, Reward: -1, Next State: 233\n",
      "Action: 3, Reward: -1, Next State: 213\n",
      "Action: 4, Reward: -10, Next State: 213\n",
      "Action: 5, Reward: -10, Next State: 213\n",
      "Action: 2, Reward: -1, Next State: 233\n",
      "Action: 0, Reward: -1, Next State: 333\n",
      "Action: 2, Reward: -1, Next State: 353\n",
      "Action: 1, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 4, Reward: -10, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 3, Reward: -1, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 4, Reward: -10, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 3, Reward: -1, Next State: 253\n",
      "Action: 5, Reward: -10, Next State: 253\n",
      "Action: 1, Reward: -1, Next State: 153\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 1, Reward: -1, Next State: 53\n",
      "Action: 0, Reward: -1, Next State: 153\n",
      "Action: 2, Reward: -1, Next State: 173\n",
      "Action: 3, Reward: -1, Next State: 153\n",
      "Action: 0, Reward: -1, Next State: 253\n",
      "Action: 2, Reward: -1, Next State: 273\n",
      "Action: 5, Reward: -10, Next State: 273\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 1, Reward: -1, Next State: 193\n",
      "Action: 5, Reward: -10, Next State: 193\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 3, Reward: -1, Next State: 173\n",
      "Action: 1, Reward: -1, Next State: 73\n",
      "Action: 2, Reward: -1, Next State: 93\n",
      "Action: 0, Reward: -1, Next State: 193\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 5, Reward: -10, Next State: 193\n",
      "Action: 2, Reward: -1, Next State: 193\n",
      "Action: 4, Reward: -10, Next State: 193\n",
      "Action: 0, Reward: -1, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 0, Reward: -1, Next State: 393\n",
      "Action: 5, Reward: -10, Next State: 393\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 5, Reward: -10, Next State: 393\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 0, Reward: -1, Next State: 493\n",
      "Action: 1, Reward: -1, Next State: 393\n",
      "Action: 5, Reward: -10, Next State: 393\n",
      "Action: 5, Reward: -10, Next State: 393\n",
      "Action: 4, Reward: -10, Next State: 393\n",
      "Action: 5, Reward: -10, Next State: 393\n",
      "Action: 5, Reward: -10, Next State: 393\n",
      "Action: 0, Reward: -1, Next State: 493\n",
      "Action: 2, Reward: -1, Next State: 493\n",
      "Action: 3, Reward: -1, Next State: 473\n",
      "Action: 1, Reward: -1, Next State: 373\n",
      "Action: 4, Reward: -10, Next State: 373\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 4, Reward: -10, Next State: 373\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 2, Reward: -1, Next State: 393\n",
      "Action: 1, Reward: -1, Next State: 293\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 4, Reward: -10, Next State: 293\n",
      "Action: 2, Reward: -1, Next State: 293\n",
      "Action: 0, Reward: -1, Next State: 393\n",
      "Action: 4, Reward: -10, Next State: 393\n",
      "Action: 0, Reward: -1, Next State: 493\n",
      "Action: 3, Reward: -1, Next State: 473\n",
      "Action: 1, Reward: -1, Next State: 373\n",
      "Action: 5, Reward: -10, Next State: 373\n",
      "Action: 3, Reward: -1, Next State: 373\n",
      "Action: 0, Reward: -1, Next State: 473\n",
      "Action: 4, Reward: -1, Next State: 477\n",
      "Action: 3, Reward: -1, Next State: 477\n",
      "Action: 3, Reward: -1, Next State: 477\n",
      "Action: 1, Reward: -1, Next State: 377\n",
      "Action: 0, Reward: -1, Next State: 477\n",
      "Action: 4, Reward: -10, Next State: 477\n",
      "Action: 3, Reward: -1, Next State: 477\n",
      "Action: 0, Reward: -1, Next State: 477\n",
      "Action: 3, Reward: -1, Next State: 477\n",
      "Action: 1, Reward: -1, Next State: 377\n",
      "Action: 4, Reward: -10, Next State: 377\n",
      "Action: 0, Reward: -1, Next State: 477\n",
      "Action: 2, Reward: -1, Next State: 497\n",
      "Action: 1, Reward: -1, Next State: 397\n",
      "Action: 2, Reward: -1, Next State: 397\n",
      "Action: 1, Reward: -1, Next State: 297\n",
      "Action: 1, Reward: -1, Next State: 197\n",
      "Action: 4, Reward: -10, Next State: 197\n",
      "Action: 2, Reward: -1, Next State: 197\n",
      "Action: 3, Reward: -1, Next State: 177\n",
      "Action: 5, Reward: -10, Next State: 177\n",
      "Action: 1, Reward: -1, Next State: 77\n",
      "Action: 3, Reward: -1, Next State: 57\n",
      "Action: 1, Reward: -1, Next State: 57\n",
      "Action: 3, Reward: -1, Next State: 57\n",
      "Action: 0, Reward: -1, Next State: 157\n",
      "Action: 4, Reward: -10, Next State: 157\n",
      "Action: 2, Reward: -1, Next State: 177\n",
      "Action: 5, Reward: -10, Next State: 177\n",
      "Action: 4, Reward: -10, Next State: 177\n",
      "Action: 4, Reward: -10, Next State: 177\n",
      "Action: 2, Reward: -1, Next State: 197\n",
      "Action: 0, Reward: -1, Next State: 297\n",
      "Action: 2, Reward: -1, Next State: 297\n",
      "Action: 1, Reward: -1, Next State: 197\n",
      "Action: 5, Reward: -10, Next State: 197\n",
      "Action: 4, Reward: -10, Next State: 197\n",
      "Action: 4, Reward: -10, Next State: 197\n",
      "Action: 0, Reward: -1, Next State: 297\n",
      "Action: 0, Reward: -1, Next State: 397\n",
      "Action: 0, Reward: -1, Next State: 497\n",
      "Action: 3, Reward: -1, Next State: 477\n",
      "Action: 4, Reward: -10, Next State: 477\n",
      "Action: 0, Reward: -1, Next State: 477\n",
      "Action: 1, Reward: -1, Next State: 377\n",
      "Action: 3, Reward: -1, Next State: 377\n",
      "Action: 5, Reward: -10, Next State: 377\n",
      "Action: 5, Reward: -10, Next State: 377\n",
      "Action: 5, Reward: -10, Next State: 377\n",
      "Action: 2, Reward: -1, Next State: 397\n",
      "Action: 0, Reward: -1, Next State: 497\n",
      "Action: 1, Reward: -1, Next State: 397\n",
      "Action: 4, Reward: -10, Next State: 397\n",
      "Action: 0, Reward: -1, Next State: 497\n",
      "Action: 5, Reward: -10, Next State: 497\n",
      "Action: 2, Reward: -1, Next State: 497\n",
      "Action: 4, Reward: -10, Next State: 497\n",
      "Action: 1, Reward: -1, Next State: 397\n",
      "Action: 3, Reward: -1, Next State: 377\n",
      "Action: 4, Reward: -10, Next State: 377\n",
      "Action: 2, Reward: -1, Next State: 397\n",
      "Action: 3, Reward: -1, Next State: 377\n",
      "Action: 1, Reward: -1, Next State: 277\n",
      "Action: 5, Reward: -10, Next State: 277\n",
      "Action: 1, Reward: -1, Next State: 177\n",
      "Action: 5, Reward: -10, Next State: 177\n",
      "Action: 2, Reward: -1, Next State: 197\n",
      "Action: 1, Reward: -1, Next State: 97\n",
      "Action: 5, Reward: 20, Next State: 85\n",
      "Total reward: -7921\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "# Create the Taxi environment\n",
    "env = gym.make('Taxi-v3')\n",
    "\n",
    "# Reset the environment to start a new episode\n",
    "state, info = env.reset()  # Reset now returns (state, info)\n",
    "\n",
    "# Render the initial state of the environment\n",
    "print(\"Initial State:\")\n",
    "env.render()\n",
    "\n",
    "# Interact with the environment by taking random actions\n",
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "while not done:\n",
    "    # Take a random action\n",
    "    action = env.action_space.sample()  # Random action\n",
    "    next_state, reward, done, truncated, info = env.step(action)  # Step returns a 5-tuple\n",
    "\n",
    "    # Accumulate the reward\n",
    "    total_reward += reward\n",
    "\n",
    "    # Print out the current step information\n",
    "    print(f\"Action: {action}, Reward: {reward}, Next State: {next_state}\")\n",
    "    env.render()  # Render the environment to see the new state\n",
    "\n",
    "# Print the total reward after the episode ends\n",
    "print(f\"Total reward: {total_reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward after 3 moves: -12\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Create the Taxi environment\n",
    "env = gym.make('Taxi-v3')\n",
    "\n",
    "# Function to decode the state from integer representation\n",
    "def decode_state(state):\n",
    "    # The Taxi environment is a 5x5 grid, with 4 possible locations for passengers (0-4)\n",
    "    # and 4 possible locations for the destination (0-4).\n",
    "    # Total state space: 5x5x5x5x4 = 500 states.\n",
    "\n",
    "    grid_size = 5\n",
    "    passenger_positions = 4\n",
    "    destination_positions = 4\n",
    "\n",
    "    # Decode the state (state is a single integer)\n",
    "    taxi_pos = state % (grid_size * grid_size)  # Taxi's position (0-24)\n",
    "    passenger_idx = (state // (grid_size * grid_size)) % passenger_positions  # Passenger's location (0-4)\n",
    "    destination_idx = (state // (grid_size * grid_size * passenger_positions)) % destination_positions  # Destination's location (0-4)\n",
    "    \n",
    "    taxi_row, taxi_col = divmod(taxi_pos, grid_size)  # Taxi's row and column\n",
    "    passenger_pos = passenger_idx  # Passenger's position (integer representation)\n",
    "    destination_pos = destination_idx  # Destination's position (integer representation)\n",
    "\n",
    "    return taxi_row, taxi_col, passenger_pos, destination_pos\n",
    "\n",
    "# Function to render the environment as a plot\n",
    "def render_grid(state):\n",
    "    grid_size = 5\n",
    "    taxi_row, taxi_col, passenger_pos, destination_pos = decode_state(state)\n",
    "    \n",
    "    # Create a 5x5 grid\n",
    "    grid = np.zeros((grid_size, grid_size))\n",
    "\n",
    "    # Mark taxi, passenger, and destination positions\n",
    "    grid[taxi_row, taxi_col] = 1  # Taxi's position (1)\n",
    "    grid[passenger_pos // grid_size, passenger_pos % grid_size] = 2  # Passenger's position (2)\n",
    "    grid[destination_pos // grid_size, destination_pos % grid_size] = 3  # Destination's position (3)\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(grid, cmap=\"viridis\", origin=\"upper\", extent=(0, grid_size, 0, grid_size))\n",
    "    \n",
    "    # Grid labels and settings\n",
    "    plt.grid(True)\n",
    "    plt.xticks(range(5))\n",
    "    plt.yticks(range(5))\n",
    "\n",
    "    # Add text labels for taxi (T), passenger (P), and destination (D)\n",
    "    plt.text(taxi_col, taxi_row, \"T\", ha='center', va='center', fontsize=12, color='white')\n",
    "    plt.text(passenger_pos % grid_size, passenger_pos // grid_size, \"P\", ha='center', va='center', fontsize=12, color='white')\n",
    "    plt.text(destination_pos % grid_size, destination_pos // grid_size, \"D\", ha='center', va='center', fontsize=12, color='white')\n",
    "\n",
    "    plt.title(\"Taxi Environment\")\n",
    "    plt.show()\n",
    "\n",
    "# Reset the environment and start an episode\n",
    "state, info = env.reset()  # This will return state as an integer and info as a dictionary\n",
    "done = False\n",
    "total_reward = 0\n",
    "moves = 0  # To keep track of the number of moves\n",
    "\n",
    "# Interact with the environment by taking random actions\n",
    "while not done and moves < 3:  # Limit to 3 moves\n",
    "    # Render the environment\n",
    "    render_grid(state)\n",
    "    \n",
    "    # Take a random action\n",
    "    action = env.action_space.sample()  # Random action\n",
    "    next_state, reward, done, truncated, info = env.step(action)  # Step the environment\n",
    "    \n",
    "    # Accumulate reward\n",
    "    total_reward += reward\n",
    "    \n",
    "    # Update the state\n",
    "    state = next_state\n",
    "\n",
    "    # Increment move counter\n",
    "    moves += 1\n",
    "\n",
    "    # Pause to create animation effect\n",
    "    time.sleep(1)\n",
    "\n",
    "# Print the total reward after the episode ends\n",
    "print(f\"Total reward after {moves} moves: {total_reward}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Setting Up the RL Agent: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100/1000, Total Reward: -118\n",
      "Episode 200/1000, Total Reward: -145\n",
      "Episode 300/1000, Total Reward: -121\n",
      "Episode 400/1000, Total Reward: -112\n",
      "Episode 500/1000, Total Reward: -50\n",
      "Episode 600/1000, Total Reward: -139\n",
      "Episode 700/1000, Total Reward: -12\n",
      "Episode 800/1000, Total Reward: 5\n",
      "Episode 900/1000, Total Reward: -208\n",
      "Episode 1000/1000, Total Reward: -12\n",
      "Testing learned policy:\n",
      "Total reward after training: 12\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Create the Taxi environment\n",
    "env = gym.make('Taxi-v3')\n",
    "\n",
    "# Initialize the Q-table with zeros: (state_space, action_space)\n",
    "state_space = env.observation_space.n  # Total number of states (500 for Taxi-v3)\n",
    "action_space = env.action_space.n  # Total number of actions (6 for Taxi-v3)\n",
    "Q = np.zeros((state_space, action_space))\n",
    "\n",
    "# Hyperparameters for Q-learning\n",
    "alpha = 0.1  # Learning rate\n",
    "gamma = 0.99  # Discount factor\n",
    "epsilon = 0.1  # Exploration rate (epsilon-greedy)\n",
    "episodes = 1000  # Number of episodes to train the agent\n",
    "max_steps_per_episode = 100  # Max steps per episode\n",
    "\n",
    "# Epsilon-greedy action selection\n",
    "def epsilon_greedy(state):\n",
    "    if random.uniform(0, 1) < epsilon:\n",
    "        return env.action_space.sample()  # Explore: take random action\n",
    "    else:\n",
    "        return np.argmax(Q[state])  # Exploit: take action with highest Q-value\n",
    "\n",
    "# Train the agent\n",
    "for episode in range(episodes):\n",
    "    state, info = env.reset()  # Reset the environment and get the initial state\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    for step in range(max_steps_per_episode):\n",
    "        action = epsilon_greedy(state)  # Select action based on epsilon-greedy policy\n",
    "        next_state, reward, done, truncated, info = env.step(action)  # Take action\n",
    "        \n",
    "        # Update Q-value using the Q-learning formula\n",
    "        best_next_action = np.argmax(Q[next_state])  # Max Q-value for next state\n",
    "        Q[state, action] = Q[state, action] + alpha * (reward + gamma * Q[next_state, best_next_action] - Q[state, action])\n",
    "        \n",
    "        total_reward += reward\n",
    "        state = next_state  # Move to the next state\n",
    "        \n",
    "        if done:  # If the episode is done\n",
    "            break\n",
    "    \n",
    "    # Print the total reward at the end of each episode\n",
    "    if (episode + 1) % 100 == 0:\n",
    "        print(f\"Episode {episode + 1}/{episodes}, Total Reward: {total_reward}\")\n",
    "\n",
    "# Test the learned policy (after training)\n",
    "state, info = env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "print(\"Testing learned policy:\")\n",
    "while not done:\n",
    "    action = np.argmax(Q[state])  # Choose the best action based on learned Q-table\n",
    "    next_state, reward, done, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    state = next_state\n",
    "    env.render()  # Optionally render the environment to visualize the steps\n",
    "\n",
    "print(f\"Total reward after training: {total_reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100/1000, Total Reward: -118\n",
      "Episode 200/1000, Total Reward: -154\n",
      "Episode 300/1000, Total Reward: 7\n",
      "Episode 400/1000, Total Reward: -127\n",
      "Episode 500/1000, Total Reward: -118\n",
      "Episode 600/1000, Total Reward: -136\n",
      "Episode 700/1000, Total Reward: -136\n",
      "Episode 800/1000, Total Reward: -16\n",
      "Episode 900/1000, Total Reward: -55\n",
      "Episode 1000/1000, Total Reward: 1\n",
      "Testing learned policy:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 61\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting learned policy:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m---> 61\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Exploit the learned policy (choose the action with the highest Q-value)\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     next_state, reward, done, truncated, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m     63\u001b[0m     total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:1359\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1270\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1271\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[0;32m   1272\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1356\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[0;32m   1357\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1358\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m-> 1359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Create the Taxi environment\n",
    "env = gym.make('Taxi-v3')\n",
    "\n",
    "# Initialize the Q-table with zeros: (state_space, action_space)\n",
    "state_space = env.observation_space.n  # Number of possible states (500)\n",
    "action_space = env.action_space.n  # Number of possible actions (6)\n",
    "Q = np.zeros((state_space, action_space))  # Initialize the Q-table\n",
    "\n",
    "# Hyperparameters for Q-learning\n",
    "alpha = 0.1  # Learning rate (how much new information overrides the old)\n",
    "gamma = 0.99  # Discount factor (how much we care about future rewards)\n",
    "epsilon = 0.1  # Exploration rate (probability of exploring instead of exploiting)\n",
    "episodes = 1000  # Number of episodes to train the agent\n",
    "max_steps_per_episode = 100  # Max steps per episode\n",
    "\n",
    "# Epsilon-greedy action selection function\n",
    "def epsilon_greedy(state):\n",
    "    if random.uniform(0, 1) < epsilon:\n",
    "        return env.action_space.sample()  # Explore: take a random action\n",
    "    else:\n",
    "        return np.argmax(Q[state])  # Exploit: take action with highest Q-value\n",
    "\n",
    "# Train the agent\n",
    "for episode in range(episodes):\n",
    "    state, info = env.reset()  # Reset the environment at the start of each episode\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    for step in range(max_steps_per_episode):\n",
    "        # Select an action based on epsilon-greedy policy\n",
    "        action = epsilon_greedy(state)\n",
    "        \n",
    "        # Take the action and observe the reward and next state\n",
    "        next_state, reward, done, truncated, info = env.step(action)\n",
    "        \n",
    "        # Q-value update using the Q-learning formula\n",
    "        best_next_action = np.argmax(Q[next_state])  # Max Q-value for next state\n",
    "        Q[state, action] = Q[state, action] + alpha * (reward + gamma * Q[next_state, best_next_action] - Q[state, action])\n",
    "        \n",
    "        total_reward += reward\n",
    "        state = next_state  # Update the state to the next state\n",
    "        \n",
    "        if done:  # If the episode is done, break out of the loop\n",
    "            break\n",
    "    \n",
    "    # Optionally, print the total reward for every 100th episode\n",
    "    if (episode + 1) % 100 == 0:\n",
    "        print(f\"Episode {episode + 1}/{episodes}, Total Reward: {total_reward}\")\n",
    "\n",
    "# Optionally: Testing phase (after training)\n",
    "state, info = env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "print(\"Testing learned policy:\")\n",
    "while not done:\n",
    "    action = np.argmax(Q[state])  # Exploit the learned policy (choose the action with the highest Q-value)\n",
    "    next_state, reward, done, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    state = next_state\n",
    "    env.render()  # Optionally render the environment to visualize the steps\n",
    "\n",
    "print(f\"Total reward after training: {total_reward}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the RL Agent:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Train the RL agent on the Taxi-v3 environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100/1000, Total Reward: -118\n",
      "Episode 200/1000, Total Reward: -84\n",
      "Episode 300/1000, Total Reward: -127\n",
      "Episode 400/1000, Total Reward: -154\n",
      "Episode 500/1000, Total Reward: -127\n",
      "Episode 600/1000, Total Reward: -136\n",
      "Episode 700/1000, Total Reward: -154\n",
      "Episode 800/1000, Total Reward: -136\n",
      "Episode 900/1000, Total Reward: -3\n",
      "Episode 1000/1000, Total Reward: -53\n",
      "Testing learned policy:\n",
      "Total reward after training: 11\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Create the Taxi environment\n",
    "env = gym.make('Taxi-v3')\n",
    "\n",
    "# Initialize the Q-table with zeros: (state_space, action_space)\n",
    "state_space = env.observation_space.n  # Number of possible states (500)\n",
    "action_space = env.action_space.n  # Number of possible actions (6)\n",
    "Q = np.zeros((state_space, action_space))  # Initialize the Q-table\n",
    "\n",
    "# Hyperparameters for Q-learning\n",
    "alpha = 0.1  # Learning rate (how much new information overrides the old)\n",
    "gamma = 0.99  # Discount factor (how much we care about future rewards)\n",
    "epsilon = 0.1  # Exploration rate (probability of exploring instead of exploiting)\n",
    "episodes = 1000  # Number of episodes to train the agent\n",
    "max_steps_per_episode = 100  # Max steps per episode\n",
    "\n",
    "# Epsilon-greedy action selection function\n",
    "def epsilon_greedy(state):\n",
    "    if random.uniform(0, 1) < epsilon:\n",
    "        return env.action_space.sample()  # Explore: take a random action\n",
    "    else:\n",
    "        return np.argmax(Q[state])  # Exploit: take action with highest Q-value\n",
    "\n",
    "# Training the agent\n",
    "for episode in range(episodes):\n",
    "    state, info = env.reset()  # Reset the environment at the start of each episode\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    for step in range(max_steps_per_episode):\n",
    "        # Select an action based on epsilon-greedy policy\n",
    "        action = epsilon_greedy(state)\n",
    "        \n",
    "        # Take the action and observe the reward and next state\n",
    "        next_state, reward, done, truncated, info = env.step(action)\n",
    "        \n",
    "        # Q-value update using the Q-learning formula\n",
    "        best_next_action = np.argmax(Q[next_state])  # Max Q-value for next state\n",
    "        Q[state, action] = Q[state, action] + alpha * (reward + gamma * Q[next_state, best_next_action] - Q[state, action])\n",
    "        \n",
    "        total_reward += reward\n",
    "        state = next_state  # Update the state to the next state\n",
    "        \n",
    "        if done:  # If the episode is done, break out of the loop\n",
    "            break\n",
    "    \n",
    "    # Optionally, print the total reward for every 100th episode\n",
    "    if (episode + 1) % 100 == 0:\n",
    "        print(f\"Episode {episode + 1}/{episodes}, Total Reward: {total_reward}\")\n",
    "\n",
    "# Optionally: Testing phase (after training)\n",
    "state, info = env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "print(\"Testing learned policy:\")\n",
    "while not done:\n",
    "    action = np.argmax(Q[state])  # Exploit the learned policy (choose the action with the highest Q-value)\n",
    "    next_state, reward, done, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    state = next_state\n",
    "    env.render()  # Optionally render the environment to visualize the steps\n",
    "\n",
    "print(f\"Total reward after training: {total_reward}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Tune hyperparameters such as learning rate, discount factor, and exploration \n",
    "strategy (ε-greedy). \n",
    "\n",
    "Q-learning with Tuned Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the Taxi environment\n",
    "env = gym.make('Taxi-v3')\n",
    "\n",
    "# Hyperparameters for Q-learning (These values will be tuned)\n",
    "alphas = [0.1, 0.2, 0.3]  # Learning rates to test\n",
    "gammas = [0.9, 0.95, 0.99]  # Discount factors to test\n",
    "epsilons = [0.1, 0.2, 0.3]  # Exploration rates to test\n",
    "episodes = 1000  # Number of episodes to train the agent\n",
    "max_steps_per_episode = 100  # Max steps per episode\n",
    "\n",
    "# Function to train the agent with specific hyperparameters\n",
    "def train_agent(alpha, gamma, epsilon):\n",
    "    state_space = env.observation_space.n  # Number of possible states (500)\n",
    "    action_space = env.action_space.n  # Number of possible actions (6)\n",
    "    Q = np.zeros((state_space, action_space))  # Initialize the Q-table\n",
    "\n",
    "    # Epsilon-greedy action selection function\n",
    "    def epsilon_greedy(state):\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            return env.action_space.sample()  # Explore: take a random action\n",
    "        else:\n",
    "            return np.argmax(Q[state])  # Exploit: take action with highest Q-value\n",
    "    \n",
    "    # Training loop\n",
    "    total_rewards = []  # To track rewards across episodes\n",
    "    for episode in range(episodes):\n",
    "        state, info = env.reset()  # Reset the environment at the start of each episode\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        \n",
    "        for step in range(max_steps_per_episode):\n",
    "            # Select an action based on epsilon-greedy policy\n",
    "            action = epsilon_greedy(state)\n",
    "            \n",
    "            # Take the action and observe the reward and next state\n",
    "            next_state, reward, done, truncated, info = env.step(action)\n",
    "            \n",
    "            # Q-value update using the Q-learning formula\n",
    "            best_next_action = np.argmax(Q[next_state])  # Max Q-value for next state\n",
    "            Q[state, action] = Q[state, action] + alpha * (reward + gamma * Q[next_state, best_next_action] - Q[state, action])\n",
    "            \n",
    "            total_reward += reward\n",
    "            state = next_state  # Update the state to the next state\n",
    "            \n",
    "            if done:  # If the episode is done, break out of the loop\n",
    "                break\n",
    "        \n",
    "        total_rewards.append(total_reward)  # Track total reward for the episode\n",
    "\n",
    "        # Optionally, print the total reward for every 100th episode\n",
    "        if (episode + 1) % 100 == 0:\n",
    "            print(f\"Alpha: {alpha}, Gamma: {gamma}, Epsilon: {epsilon}, Episode {episode + 1}/{episodes}, Total Reward: {total_reward}\")\n",
    "\n",
    "    # Return the total rewards for each episode for analysis\n",
    "    return total_rewards\n",
    "\n",
    "# Tune hyperparameters\n",
    "# We will store the total rewards for different combinations\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
